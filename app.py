from flask import Flask, render_template, request, jsonify, send_file, make_response, send_from_directory
import logging
import re
# Force reload
# te3
import sqlite3
import requests
import json
import time
import smtplib
import hashlib
import os
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, timedelta
from threading import Thread
from werkzeug.utils import secure_filename
from ai_config import AI_CONFIG, get_model_config, switch_to_backup_api
from database import get_db, close_db, DatabasePool
from api_utils import api_response, validate_json, cached
from concurrent.futures import ThreadPoolExecutor
import uuid
from storage_service import storage_service

app = Flask(__name__)
app.teardown_appcontext(close_db)

# æ³¨å†Œè“å›¾
@app.route('/debug/routes')
def list_routes():
    import urllib
    output = []
    for rule in app.url_map.iter_rules():
        methods = ','.join(rule.methods)
        line = urllib.parse.unquote("{:50s} {:20s} {}".format(rule.endpoint, methods, rule))
        output.append(line)
    return "<pre>" + "\n".join(output) + "</pre>"

@app.route('/debug/static-info')
def debug_static_info():
    import os
    static_dir = os.path.join(app.root_path, 'static')
    js_dir = os.path.join(static_dir, 'js')
    
    info = {
        'root_path': app.root_path,
        'static_exists': os.path.exists(static_dir),
        'js_exists': os.path.exists(js_dir),
        'js_files': os.listdir(js_dir) if os.path.exists(js_dir) else []
    }
    return jsonify(info)

@app.route('/api/force_static/<path:filename>')
def force_static(filename):
    return send_from_directory(os.path.join(app.root_path, 'static'), filename)

from routes.project_routes import project_bp
from routes.member_routes import member_bp
from routes.log_routes import log_bp
from routes.doc_routes import doc_bp
from routes.lifecycle_routes import lifecycle_bp
from routes.task_routes import task_bp
from routes.analytics_routes import analytics_bp
from routes.monitor_routes import monitor_bp
from routes.standup_routes import standup_bp
from routes.gantt_routes import gantt_bp
from routes.ai_insight_routes import ai_insight_bp
from services.project_service import project_service
from services.ai_service import ai_service
from routes.nl_query_routes import nl_query_bp
from routes.financial_routes import financial_bp
from routes.pmo_routes import pmo_bp
from routes.report_routes import report_bp
from routes.risk_simulation_routes import risk_bp
from routes.collaboration_routes import collab_bp
from routes.operational_routes import operational_bp
from services.analytics_service import analytics_service
from services.monitor_service import monitor_service
from app_config import NOTIFICATION_CONFIG, PROJECT_STATUS, PROJECT_TEMPLATES
app.register_blueprint(project_bp)
app.register_blueprint(member_bp)
app.register_blueprint(log_bp)
app.register_blueprint(doc_bp)
app.register_blueprint(lifecycle_bp)
app.register_blueprint(task_bp)
app.register_blueprint(analytics_bp)
app.register_blueprint(monitor_bp)
app.register_blueprint(standup_bp)
app.register_blueprint(gantt_bp)
app.register_blueprint(ai_insight_bp)
app.register_blueprint(nl_query_bp)
app.register_blueprint(financial_bp)
app.register_blueprint(pmo_bp)
app.register_blueprint(report_bp)
app.register_blueprint(risk_bp)
app.register_blueprint(collab_bp)
app.register_blueprint(operational_bp)

# thread executor for async tasks
executor = ThreadPoolExecutor(max_workers=4)
# in-memory task result store (should use Redis in production)
task_results = {}

# DATABASE constant moved to database.py
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'pdf', 'doc', 'docx', 'xls', 'xlsx', 'ppt', 'pptx', 'txt', 'png', 'jpg', 'jpeg', 'zip', 'rar'}

# ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 500 * 1024 * 1024  # 500MB

# ========== AI é…ç½® (DeepSeek) ==========
# AI_CONFIG å·²ç§»è‡³ ai_config.py ç»Ÿä¸€ç®¡ç†

# NOTIFICATION_CONFIG, PROJECT_STATUS, PROJECT_TEMPLATES å·²ç§»è‡³ app_config.py ç»Ÿä¸€ç®¡ç†

# get_db is now imported from database.py

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def reload_notification_config():
    """ä»æ•°æ®åº“åŠ è½½å¹¶åŒæ­¥ç³»ç»Ÿé€šçŸ¥é…ç½®"""
    try:
        from app_config import NOTIFICATION_CONFIG
        with DatabasePool.get_connection() as conn:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            cursor = conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='system_config'")
            if not cursor.fetchone():
                return
                
            configs = conn.execute("SELECT config_key, value FROM system_config").fetchall()
            for row in configs:
                key = row['config_key']
                val = row['value']
                if key == 'wecom_webhook':
                    NOTIFICATION_CONFIG['WECOM_WEBHOOK'] = val
                elif key == 'wecom_enabled':
                    NOTIFICATION_CONFIG['ENABLE_WECOM'] = val.lower() == 'true'
            # logger.info("é€šçŸ¥é…ç½®åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"Error loading notification config: {e}")

def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“å¹¶è¿›è¡Œå¿…è¦çš„å‡çº§"""
    conn = get_db()
    cursor = conn.cursor()
    
    # 0. ç³»ç»Ÿé…ç½®è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS system_config (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            config_key TEXT UNIQUE,
            value TEXT,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # 1. é¡¹ç›®ä¸»è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS projects (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_no TEXT UNIQUE,
            project_name TEXT NOT NULL,
            hospital_name TEXT NOT NULL,
            contract_amount REAL,
            project_manager TEXT,
            contact_person TEXT,
            contact_phone TEXT,
            plan_start_date DATE,
            plan_end_date DATE,
            actual_start_date DATE,
            actual_end_date DATE,
            status TEXT DEFAULT 'å¾…å¯åŠ¨',
            progress INTEGER DEFAULT 0,
            priority TEXT DEFAULT 'æ™®é€š',
            icu_beds INTEGER DEFAULT 0,
            operating_rooms INTEGER DEFAULT 0,
            pacu_beds INTEGER DEFAULT 0,
            province TEXT,
            city TEXT,
            address TEXT,
            contract_no TEXT,
            data_hash TEXT,
            risk_score REAL DEFAULT 0,
            risk_analysis TEXT,
            share_token TEXT UNIQUE,
            share_enabled INTEGER DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # å‡çº§è„šæœ¬ï¼šæ·»åŠ åˆ†äº«å­—æ®µ
    try:
        cursor.execute("ALTER TABLE projects ADD COLUMN share_token TEXT UNIQUE")
    except: pass
    try:
        cursor.execute("ALTER TABLE projects ADD COLUMN share_enabled INTEGER DEFAULT 0")
    except: pass
    try:
        cursor.execute("ALTER TABLE projects ADD COLUMN risk_analysis TEXT")
    except: pass
    
    # 2. é¡¹ç›®é˜¶æ®µè¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS project_stages (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            stage_name TEXT NOT NULL,
            stage_order INTEGER,
            plan_start_date DATE,
            plan_end_date DATE,
            actual_start_date DATE,
            actual_end_date DATE,
            progress INTEGER DEFAULT 0,
            status TEXT DEFAULT 'å¾…å¼€å§‹',
            responsible_person TEXT,
            bonus_amount REAL DEFAULT 0,
            scale_quantity INTEGER DEFAULT 0,
            scale_unit TEXT,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')
    
    # å‡çº§è„šæœ¬ï¼šæ·»åŠ é˜¶æ®µç¼©æ”¾å­—æ®µ
    try:
        cursor.execute("ALTER TABLE project_stages ADD COLUMN scale_quantity INTEGER DEFAULT 0")
    except: pass
    try:
        cursor.execute("ALTER TABLE project_stages ADD COLUMN scale_unit TEXT")
    except: pass
    
    # 3. ä»»åŠ¡è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS tasks (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            stage_id INTEGER,
            task_name TEXT NOT NULL,
            is_completed BOOLEAN DEFAULT 0,
            completed_date DATE,
            remark TEXT,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (stage_id) REFERENCES project_stages(id)
        )
    ''')

    # 3.5. é‡Œç¨‹ç¢‘è¡¨ (è¡¥å½•)
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS milestones (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            name TEXT NOT NULL,
            target_date DATE,
            is_completed BOOLEAN DEFAULT 0,
            completed_date DATE,
            remark TEXT,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')
    
    # 4. æ¥å£å¯¹æ¥è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS interfaces (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            system_name TEXT,
            interface_name TEXT,
            status TEXT DEFAULT 'å¾…å¼€å‘',
            plan_date DATE,
            remark TEXT,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')
    
    # 5. é—®é¢˜è·Ÿè¸ªè¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS issues (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            issue_type TEXT,
            description TEXT,
            severity TEXT,
            status TEXT DEFAULT 'å¾…å¤„ç†',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            resolved_at TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')
    
    # 6. æ¶ˆæ¯æé†’è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS notifications (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            title TEXT NOT NULL,
            content TEXT,
            type TEXT DEFAULT 'info',
            is_read BOOLEAN DEFAULT 0,
            is_sent BOOLEAN DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            due_date DATE,
            remind_type TEXT DEFAULT 'once',
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 7. åŒ»ç–—è®¾å¤‡å¯¹æ¥è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS medical_devices (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            device_type TEXT,
            brand_model TEXT,
            protocol_type TEXT,
            ip_address TEXT,
            status TEXT DEFAULT 'æœªè¿æ¥',
            remark TEXT,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 8. å‘¨æŠ¥è®°å½•è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS weekly_reports (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            report_type TEXT DEFAULT 'single',
            week_start DATE,
            week_end DATE,
            content TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 9. é‡Œç¨‹ç¢‘è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS milestones (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            name TEXT NOT NULL,
            target_date DATE,
            is_completed BOOLEAN DEFAULT 0,
            completed_date DATE,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 10. è¿›åº¦å†å²è®°å½•è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS progress_history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            record_date DATE,
            progress INTEGER,
            tasks_total INTEGER,
            tasks_completed INTEGER,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 11. æŠ¥å‘Šç¼“å­˜è¡¨ (Report Cache)
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS report_cache (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            report_type TEXT,
            data_hash TEXT,
            content TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 11b. æŠ¥å‘Šå½’æ¡£è¡¨ (Report Archive - æ°¸ä¹…æŒ‰æ—¥æœŸä¿å­˜)
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS report_archive (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            report_type TEXT,
            report_date DATE,
            content TEXT,
            generated_by TEXT DEFAULT 'auto',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # ========== V2.0 æ–°å¢è¡¨ ==========

    # 12. é¡¹ç›®æˆå‘˜è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS project_members (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            name TEXT NOT NULL,
            role TEXT,
            phone TEXT,
            email TEXT,
            join_date DATE,
            leave_date DATE,
            is_onsite BOOLEAN DEFAULT 0,
            status TEXT DEFAULT 'åœ¨å²—',
            remark TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 13. ç”²æ–¹è”ç³»äººè¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS customer_contacts (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            name TEXT NOT NULL,
            department TEXT,
            position TEXT,
            phone TEXT,
            email TEXT,
            is_primary BOOLEAN DEFAULT 0,
            remark TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 14. ç¦»åœºè®°å½•è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS project_departures (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            departure_type TEXT,
            departure_date DATE,
            expected_return_date DATE,
            actual_return_date DATE,
            reason TEXT,
            handover_person TEXT,
            our_persons TEXT,
            doc_handover BOOLEAN DEFAULT 0,
            account_handover BOOLEAN DEFAULT 0,
            training_handover BOOLEAN DEFAULT 0,
            issue_handover BOOLEAN DEFAULT 0,
            contact_handover BOOLEAN DEFAULT 0,
            handover_doc_path TEXT,
            pending_issues TEXT,
            remote_support_info TEXT,
            status TEXT DEFAULT 'å¾…å®¡æ‰¹',
            approved_by TEXT,
            approved_at TIMESTAMP,
            remark TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 14b. é‡Œç¨‹ç¢‘å¤ç›˜è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS milestone_retrospectives (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            milestone_id INTEGER,
            project_id INTEGER,
            content TEXT,
            author TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (milestone_id) REFERENCES milestones(id),
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')
    
    # å‡çº§ milestones å¢åŠ åº†ç¥çŠ¶æ€å’Œå®Œæˆæ—¥æœŸ
    try:
        cursor.execute("ALTER TABLE milestones ADD COLUMN is_celebrated BOOLEAN DEFAULT 0")
    except: pass
    try:
        cursor.execute("ALTER TABLE milestones ADD COLUMN completed_date TEXT")
    except: pass
    
    # åç½®è¡¥å…¨é—æ¼çš„å®Œæˆæ—¥æœŸ
    try:
        cursor.execute("UPDATE milestones SET completed_date = target_date WHERE is_completed = 1 AND completed_date IS NULL")
    except: pass

    # 15. å·¥ä½œæ—¥å¿—è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS work_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            member_id INTEGER,
            member_name TEXT,
            log_date DATE,
            work_hours REAL DEFAULT 8,
            work_type TEXT DEFAULT 'ç°åœº',
            work_content TEXT,
            issues_encountered TEXT,
            tomorrow_plan TEXT,
            stage_id INTEGER,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id),
            FOREIGN KEY (member_id) REFERENCES project_members(id),
            FOREIGN KEY (stage_id) REFERENCES project_stages(id)
        )
    ''')

    # 16. é¡¹ç›®æ–‡æ¡£è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS project_documents (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            doc_name TEXT NOT NULL,
            doc_type TEXT,
            doc_category TEXT,
            file_path TEXT,
            file_size INTEGER,
            version TEXT DEFAULT 'v1.0',
            upload_by TEXT,
            upload_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            remark TEXT,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 17. é¡¹ç›®è´¹ç”¨è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS project_expenses (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            expense_date DATE,
            expense_type TEXT,
            amount REAL,
            description TEXT,
            applicant TEXT,
            receipt_path TEXT,
            status TEXT DEFAULT 'å¾…æŠ¥é”€',
            approved_by TEXT,
            approved_at TIMESTAMP,
            stage_id INTEGER,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id),
            FOREIGN KEY (stage_id) REFERENCES project_stages(id)
        )
    ''')

    # 18. é¡¹ç›®å˜æ›´è®°å½•è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS project_changes (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            change_type TEXT,
            change_title TEXT,
            change_desc TEXT,
            impact_analysis TEXT,
            requested_by TEXT,
            requested_date DATE,
            approved_by TEXT,
            approved_date DATE,
            status TEXT DEFAULT 'å¾…å®¡æ‰¹',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 19. éªŒæ”¶è®°å½•è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS project_acceptances (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            acceptance_type TEXT,
            stage_name TEXT,
            acceptance_date DATE,
            acceptance_items TEXT,
            pass_rate REAL,
            issues_found TEXT,
            customer_sign TEXT,
            our_sign TEXT,
            status TEXT DEFAULT 'å¾…éªŒæ”¶',
            remark TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 20. å®¢æˆ·æ»¡æ„åº¦è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS customer_satisfaction (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            survey_date DATE,
            survey_type TEXT,
            score_quality INTEGER,
            score_service INTEGER,
            score_response INTEGER,
            score_professional INTEGER,
            score_overall INTEGER,
            feedback TEXT,
            surveyor TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 21. æ“ä½œæ—¥å¿—è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS operation_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            operator TEXT,
            operation_type TEXT,
            entity_type TEXT,
            entity_id INTEGER,
            entity_name TEXT,
            old_value TEXT,
            new_value TEXT,
            ip_address TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')

    # 22. å›è®¿è®°å½•è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS follow_up_records (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            follow_up_date DATE,
            follow_up_type TEXT,
            contact_person TEXT,
            content TEXT,
            issues_found TEXT,
            follow_up_by TEXT,
            next_follow_up_date DATE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 23. çŸ¥è¯†åº“è¡¨ (KB)
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS knowledge_base (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            category TEXT,
            title TEXT NOT NULL,
            content TEXT NOT NULL,
            tags TEXT,
            assoc_stage TEXT,
            project_id INTEGER,
            author TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')

    # 24. ç¡¬ä»¶èµ„äº§æŠ¥è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS hardware_assets (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            asset_name TEXT NOT NULL,
            sn TEXT UNIQUE,
            model TEXT,
            status TEXT DEFAULT 'åœ¨åº“',
            location TEXT,
            responsible_person TEXT,
            purchase_date DATE,
            expire_date DATE,
            remark TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')

    # 25. AI é…ç½®è¡¨ (System Config)
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS ai_configs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT UNIQUE NOT NULL,
            api_key TEXT,
            base_url TEXT,
            models TEXT, -- JSON array
            priority INTEGER DEFAULT 10,
            is_active BOOLEAN DEFAULT 1,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')



    # 26. é¡¹ç›®æ¨¡æ¿è¡¨ - å­˜å‚¨è‡ªå®šä¹‰é¡¹ç›®æ¨¡æ¿
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS project_templates_custom (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            description TEXT,
            source_project_id INTEGER,
            template_data TEXT,
            created_by TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')

    # 27. å®¢æˆ·æ²Ÿé€šè®°å½•è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS customer_communications (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER NOT NULL,
            contact_date DATE,
            contact_person TEXT,
            contact_method TEXT,
            summary TEXT,
            related_issue_id INTEGER,
            attachments TEXT,
            created_by TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 28. ä»»åŠ¡ä¾èµ–å…³ç³»è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS task_dependencies (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            task_id INTEGER NOT NULL,
            depends_on_task_id INTEGER NOT NULL,
            dependency_type TEXT DEFAULT 'finish_to_start',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (task_id) REFERENCES tasks(id) ON DELETE CASCADE,
            FOREIGN KEY (depends_on_task_id) REFERENCES tasks(id) ON DELETE CASCADE,
            UNIQUE(task_id, depends_on_task_id)
        )
    ''')

    # 29. è¿›åº¦å¿«ç…§è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS progress_snapshots (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER NOT NULL,
            snapshot_date DATE NOT NULL,
            overall_progress INTEGER DEFAULT 0,
            snapshot_data TEXT,
            snapshot_type TEXT DEFAULT 'manual',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # 30. ç«™ä¼šçºªè¦è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS standup_minutes (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER NOT NULL,
            meeting_date DATE NOT NULL,
            content TEXT,
            ai_generated BOOLEAN DEFAULT 0,
            created_by TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects(id)
        )
    ''')

    # ========== æ•°æ®åº“å‡çº§ï¼šæ·»åŠ ç¼ºå¤±çš„åˆ— ==========
    columns_to_add = [
        ('priority', "TEXT DEFAULT 'æ™®é€š'"),
        ('icu_beds', 'INTEGER DEFAULT 0'),
        ('operating_rooms', 'INTEGER DEFAULT 0'),
        ('pacu_beds', 'INTEGER DEFAULT 0'),
        ('data_hash', 'TEXT'),
        ('province', 'TEXT'),
        ('city', 'TEXT'),
        ('address', 'TEXT'),
        ('contract_no', 'TEXT'),
        ('actual_end_date', 'DATE'),
        ('risk_score', 'REAL DEFAULT 0')
    ]
    
    # å‡çº§ï¼šé¡¹ç›®é˜¶æ®µè¡¨æ·»åŠ è´£ä»»äººå’Œå¥–é‡‘
    stage_columns = [row[1] for row in cursor.execute("PRAGMA table_info(project_stages)").fetchall()]
    if 'responsible_person' not in stage_columns:
        cursor.execute("ALTER TABLE project_stages ADD COLUMN responsible_person TEXT")
    if 'bonus_amount' not in stage_columns:
        cursor.execute("ALTER TABLE project_stages ADD COLUMN bonus_amount REAL DEFAULT 0")

    # å‡çº§ï¼šæ—¥å¿—å’Œè´¹ç”¨æ·»åŠ é˜¶æ®µå…³è”
    log_columns = [row[1] for row in cursor.execute("PRAGMA table_info(work_logs)").fetchall()]
    if 'stage_id' not in log_columns:
        cursor.execute("ALTER TABLE work_logs ADD COLUMN stage_id INTEGER")

    expense_columns = [row[1] for row in cursor.execute("PRAGMA table_info(project_expenses)").fetchall()]
    if 'stage_id' not in expense_columns:
        cursor.execute("ALTER TABLE project_expenses ADD COLUMN stage_id INTEGER")
    
    # å‡çº§ï¼šäººå‘˜è¡¨å¢åŠ å½“å‰åŸå¸‚
    member_columns = [row[1] for row in cursor.execute("PRAGMA table_info(project_members)").fetchall()]
    if 'current_city' not in member_columns:
        cursor.execute("ALTER TABLE project_members ADD COLUMN current_city TEXT")
    
    asset_columns = [row[1] for row in cursor.execute("PRAGMA table_info(hardware_assets)").fetchall()]
    if 'current_project_id' not in asset_columns:
        cursor.execute("ALTER TABLE hardware_assets ADD COLUMN current_project_id INTEGER")
    
    # å‡çº§ï¼šçŸ¥è¯†åº“å¢åŠ é™„ä»¶å’Œå¤–é“¾
    kb_columns = [row[1] for row in cursor.execute("PRAGMA table_info(knowledge_base)").fetchall()]
    if 'attachment_path' not in kb_columns:
        cursor.execute("ALTER TABLE knowledge_base ADD COLUMN attachment_path TEXT")
    if 'external_link' not in kb_columns:
        cursor.execute("ALTER TABLE knowledge_base ADD COLUMN external_link TEXT")
    if 'assoc_stage' not in kb_columns:
        cursor.execute("ALTER TABLE knowledge_base ADD COLUMN assoc_stage TEXT")
    
    existing_columns = [row[1] for row in cursor.execute("PRAGMA table_info(projects)").fetchall()]
    
    for col_name, col_def in columns_to_add:
        if col_name not in existing_columns:
            try:
                cursor.execute(f'ALTER TABLE projects ADD COLUMN {col_name} {col_def}')
                print(f"Added column {col_name} to projects table")
            except Exception as e:
                print(f"Column {col_name} might already exist: {e}")
    
    # å‡çº§ï¼šä¸ºç°æœ‰é¡¹ç›®æ·»åŠ â€˜è¡¨å•åˆ¶ä½œâ€™é˜¶æ®µ
    migrate_add_form_making_stage(cursor)
    
    conn.commit()
    
    # ========== æ€§èƒ½ä¼˜åŒ–ï¼šæ·»åŠ å¸¸ç”¨å¤–é”®ç´¢å¼• ==========
    indexes = [
        ("idx_tasks_stage_id", "tasks", "stage_id"),
        ("idx_project_stages_project_id", "project_stages", "project_id"),
        ("idx_milestones_project_id", "milestones", "project_id"),
        ("idx_interfaces_project_id", "interfaces", "project_id"),
        ("idx_issues_project_id", "issues", "project_id"),
        ("idx_medical_devices_project_id", "medical_devices", "project_id"),
        ("idx_notifications_project_id", "notifications", "project_id"),
        ("idx_documents_project_id", "documents", "project_id"),
        ("idx_project_members_project_id", "project_members", "project_id"),
        ("idx_worklogs_project_id", "worklogs", "project_id"),
        ("idx_task_deps_task_id", "task_dependencies", "task_id"),
        ("idx_task_deps_depends_on", "task_dependencies", "depends_on_task_id"),
        ("idx_snapshots_project_id", "progress_snapshots", "project_id"),
        ("idx_standup_project_id", "standup_minutes", "project_id"),
    ]
    for idx_name, table_name, column_name in indexes:
        try:
            cursor.execute(f"CREATE INDEX IF NOT EXISTS {idx_name} ON {table_name}({column_name})")
        except Exception as e:
            pass  # ç´¢å¼•å¯èƒ½å·²å­˜åœ¨æˆ–è¡¨ä¸å­˜åœ¨
    conn.commit()
    close_db()



# ========== è¾…åŠ©å‡½æ•° ==========
def migrate_add_form_making_stage(cursor):
    """ä¸ºç°æœ‰é¡¹ç›®æ·»åŠ â€˜è¡¨å•åˆ¶ä½œâ€™é˜¶æ®µ"""
    # æŸ¥æ‰¾æ²¡æœ‰â€˜è¡¨å•åˆ¶ä½œâ€™é˜¶æ®µçš„é¡¹ç›®
    projects = cursor.execute('''
        SELECT id FROM projects 
        WHERE id NOT IN (SELECT project_id FROM project_stages WHERE stage_name = 'è¡¨å•åˆ¶ä½œ')
    ''').fetchall()
    
    for p in projects:
        pid = p[0] if isinstance(p, (list, tuple)) else p['id']
        # æŸ¥æ‰¾â€˜ç³»ç»Ÿéƒ¨ç½²â€™é˜¶æ®µï¼Œç¡®å®šæ’å…¥ä½ç½®
        deployment_stage = cursor.execute('''
            SELECT stage_order, plan_end_date 
            FROM project_stages 
            WHERE project_id = ? AND stage_name = 'ç³»ç»Ÿéƒ¨ç½²'
        ''', (pid,)).fetchone()
        
        if deployment_stage:
            dep_order = deployment_stage[0] if isinstance(deployment_stage, (list, tuple)) else deployment_stage['stage_order']
            dep_end_date = deployment_stage[1] if isinstance(deployment_stage, (list, tuple)) else deployment_stage['plan_end_date']
            
            order = dep_order + 1
            # åç»­é˜¶æ®µé¡ºåº+1
            cursor.execute('''
                UPDATE project_stages SET stage_order = stage_order + 1 
                WHERE project_id = ? AND stage_order >= ?
            ''', (pid, order))
            
            # æ’å…¥â€˜è¡¨å•åˆ¶ä½œâ€™
            cursor.execute('''
                INSERT INTO project_stages (project_id, stage_name, stage_order, plan_start_date, plan_end_date, status)
                VALUES (?, 'è¡¨å•åˆ¶ä½œ', ?, ?, ?, 'å¾…å¼€å§‹')
            ''', (pid, order, dep_end_date, dep_end_date))
            
            stage_id = cursor.lastrowid
            # æ·»åŠ ä»»åŠ¡
            tasks = ['è¡¨å•è®¾è®¡è¯´æ˜ä¹¦', 'è¡¨å•é…ç½®', 'è¡¨å•æµ‹è¯•']
            for t in tasks:
                cursor.execute('INSERT INTO tasks (stage_id, task_name) VALUES (?, ?)', (stage_id, t))



def migrate_to_dynamic_milestones():
    """å°†ç°æœ‰é¡¹ç›®çš„é™æ€é‡Œç¨‹ç¢‘è¿ç§»ä¸ºåŸºäºé˜¶æ®µçš„åŠ¨æ€é‡Œç¨‹ç¢‘"""
    conn = get_db()
    cursor = conn.cursor()
    projects = cursor.execute('SELECT id FROM projects').fetchall()
    for p in projects:
        pid = p['id']
        # åˆ é™¤æ—§é‡Œç¨‹ç¢‘
        cursor.execute('DELETE FROM milestones WHERE project_id = ?', (pid,))
        # é‡æ–°åˆ›å»ºåŸºäºé˜¶æ®µçš„é‡Œç¨‹ç¢‘
        stages = cursor.execute('SELECT stage_name, plan_end_date FROM project_stages WHERE project_id = ? ORDER BY stage_order', (pid,)).fetchall()
        for s in stages:
            m_name = f"{s['stage_name']}å®Œæˆ"
            cursor.execute('INSERT INTO milestones (project_id, name, target_date) VALUES (?, ?, ?)',
                         (pid, m_name, s['plan_end_date']))
            # åŒæ­¥ä¸€æ¬¡çŠ¶æ€
            project_service.sync_project_milestones(pid, cursor)
    conn.commit()

init_db()
migrate_to_dynamic_milestones()

def log_operation(operator, op_type, entity_type, entity_id, entity_name, old_val=None, new_val=None):
    """è®°å½•æ“ä½œæ—¥å¿—"""
    conn = get_db()
    conn.execute('''
        INSERT INTO operation_logs (operator, operation_type, entity_type, entity_id, entity_name, old_value, new_value)
        VALUES (?, ?, ?, ?, ?, ?, ?)
    ''', (operator or 'ç³»ç»Ÿ', op_type, entity_type, entity_id, entity_name, 
          json.dumps(old_val, ensure_ascii=False) if old_val else None,
          json.dumps(new_val, ensure_ascii=False) if new_val else None))
    conn.commit()


# ========== Analytics and Statistics - Migrated to analytics_service


@app.route('/')
def index():
    return render_template('index.html')

# ========== é¡¹ç›®å¥åº·åº¦ä»ªè¡¨ç›˜ API ==========
@app.route('/api/dashboard/health', methods=['GET'])
def get_project_health_dashboard():
    """è·å–æ‰€æœ‰é¡¹ç›®çš„å¥åº·åº¦æŒ‡æ ‡"""
    conn = get_db()
    cursor = conn.cursor()
    
    # è·å–æ‰€æœ‰æ´»è·ƒé¡¹ç›®ï¼ˆæ’é™¤å·²å®Œæˆå’Œå·²ç»ˆæ­¢ï¼‰
    cursor.execute('''
        SELECT id, project_name, hospital_name, status, progress, 
               plan_end_date, risk_score, project_manager
        FROM projects 
        WHERE status NOT IN ('å·²å®Œæˆ', 'å·²ç»ˆæ­¢')
        ORDER BY risk_score DESC, progress ASC
    ''')
    projects = [dict(zip([c[0] for c in cursor.description], r)) for r in cursor.fetchall()]
    
    health_data = []
    today = datetime.now().date()
    
    for p in projects:
        project_id = p['id']
        
        # 1. è¿›åº¦åå·®è®¡ç®—
        try:
            plan_end = datetime.strptime(p['plan_end_date'].strip(), '%Y-%m-%d').date() if p.get('plan_end_date') and p['plan_end_date'].strip() else None
        except (ValueError, AttributeError):
            plan_end = None
        if plan_end:
            total_days = (plan_end - today).days
            expected_progress = max(0, min(100, 100 - (total_days / 90 * 100))) if total_days > 0 else 100
            progress_deviation = (p.get('progress') or 0) - expected_progress
        else:
            progress_deviation = 0
        
        # 2. é—®é¢˜æ•°é‡
        cursor.execute("SELECT COUNT(*) FROM issues WHERE project_id = ? AND status != 'å·²è§£å†³'", (project_id,))
        open_issues = cursor.fetchone()[0]
        
        # 3. æ¥å£å®Œæˆç‡
        cursor.execute("SELECT COUNT(*) FROM interfaces WHERE project_id = ?", (project_id,))
        total_interfaces = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(*) FROM interfaces WHERE project_id = ? AND status = 'å·²å®Œæˆ'", (project_id,))
        completed_interfaces = cursor.fetchone()[0]
        interface_rate = (completed_interfaces / total_interfaces * 100) if total_interfaces > 0 else 100
        
        # 4. é‡Œç¨‹ç¢‘çŠ¶æ€
        cursor.execute("""
            SELECT COUNT(*) FROM milestones 
            WHERE project_id = ? AND is_completed = 0 AND target_date < ?
        """, (project_id, today.strftime('%Y-%m-%d')))
        overdue_milestones = cursor.fetchone()[0]
        
        # 5. è®¡ç®—å¥åº·åº¦è¯„åˆ† (0-100)
        health_score = 100
        health_score -= min(30, open_issues * 5)  # æ¯ä¸ªæœªè§£å†³é—®é¢˜æ‰£5åˆ†ï¼Œæœ€å¤šæ‰£30åˆ†
        health_score -= min(20, overdue_milestones * 10)  # æ¯ä¸ªé€¾æœŸé‡Œç¨‹ç¢‘æ‰£10åˆ†ï¼Œæœ€å¤šæ‰£20åˆ†
        health_score -= min(20, max(0, -progress_deviation) * 0.5)  # è¿›åº¦è½åæ‰£åˆ†
        health_score -= min(15, (100 - interface_rate) * 0.3)  # æ¥å£æœªå®Œæˆæ‰£åˆ†
        health_score -= min(15, (p['risk_score'] or 0) * 0.3)  # é£é™©è¯„åˆ†æ‰£åˆ†
        health_score = max(0, health_score)
        
        # 6. ç¡®å®šå¥åº·çŠ¶æ€
        if health_score >= 70:
            health_status = 'green'
            health_label = 'å¥åº·'
        elif health_score >= 40:
            health_status = 'yellow'
            health_label = 'éœ€å…³æ³¨'
        else:
            health_status = 'red'
            health_label = 'é£é™©'
        
        health_data.append({
            'id': project_id,
            'project_name': p['project_name'],
            'hospital_name': p['hospital_name'],
            'status': p['status'],
            'progress': p['progress'] or 0,
            'project_manager': p['project_manager'],
            'health_score': round(health_score),
            'health_status': health_status,
            'health_label': health_label,
            'metrics': {
                'open_issues': open_issues,
                'overdue_milestones': overdue_milestones,
                'interface_rate': round(interface_rate),
                'risk_score': p['risk_score'] or 0,
                'progress_deviation': round(progress_deviation)
            }
        })
    
    # æ±‡æ€»ç»Ÿè®¡
    summary = {
        'total': len(health_data),
        'green': sum(1 for h in health_data if h['health_status'] == 'green'),
        'yellow': sum(1 for h in health_data if h['health_status'] == 'yellow'),
        'red': sum(1 for h in health_data if h['health_status'] == 'red')
    }
    
    close_db()
    return api_response(True, {'projects': health_data, 'summary': summary})

# ========== æ™ºèƒ½é¢„è­¦ API ==========
@app.route('/api/warnings', methods=['GET'])
def get_project_warnings():
    """è·å–æ‰€æœ‰é¡¹ç›®çš„é¢„è­¦ä¿¡æ¯"""
    try:
        from services.warning_service import warning_service
        data = warning_service.get_warning_summary()
        return api_response(True, data)
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/warnings/count', methods=['GET'])
def get_warning_count():
    """è·å–é¢„è­¦æ•°é‡ï¼ˆç”¨äºè§’æ ‡æ˜¾ç¤ºï¼‰"""
    try:
        from services.warning_service import warning_service
        warnings = warning_service.get_all_warnings()
        high_count = sum(1 for w in warnings if w['severity'] == 'high')
        return api_response(True, {'total': len(warnings), 'high': high_count})
    except Exception as e:
        return api_response(True, {'total': 0, 'high': 0})

# ========== é¡¹ç›®æ¨¡æ¿ API ==========
@app.route('/api/templates', methods=['GET'])
def get_project_templates():
    """è·å–æ‰€æœ‰è‡ªå®šä¹‰é¡¹ç›®æ¨¡æ¿"""
    conn = get_db()
    templates = conn.execute('SELECT * FROM project_templates_custom ORDER BY created_at DESC').fetchall()
    close_db()
    return api_response(True, [dict(t) for t in templates])

@app.route('/api/projects/<int:project_id>/save-as-template', methods=['POST'])
def save_project_as_template(project_id):
    """å°†é¡¹ç›®ä¿å­˜ä¸ºæ¨¡æ¿"""
    import json
    data = request.json
    conn = get_db()
    cursor = conn.cursor()
    
    # è·å–é¡¹ç›®åŸºæœ¬ä¿¡æ¯
    project = cursor.execute('SELECT * FROM projects WHERE id = ?', (project_id,)).fetchone()
    if not project:
        close_db()
        return api_response(False, message='é¡¹ç›®ä¸å­˜åœ¨', code=404)
    
    # è·å–é˜¶æ®µå’Œä»»åŠ¡
    stages = cursor.execute('SELECT * FROM project_stages WHERE project_id = ?', (project_id,)).fetchall()
    stages_data = []
    for stage in stages:
        tasks = cursor.execute('SELECT task_name, is_completed FROM tasks WHERE stage_id = ?', (stage['id'],)).fetchall()
        stages_data.append({
            'name': stage['stage_name'],
            'order_num': stage['stage_order'],
            'tasks': [{'name': t['task_name']} for t in tasks]
        })
    
    # è·å–é‡Œç¨‹ç¢‘æ¨¡æ¿
    milestones = cursor.execute('SELECT name FROM milestones WHERE project_id = ?', (project_id,)).fetchall()
    
    # ç»„è£…æ¨¡æ¿æ•°æ®
    template_data = {
        'stages': stages_data,
        'milestones': [{'name': m['name']} for m in milestones],
        'icu_beds': project['icu_beds'],
        'operating_rooms': project['operating_rooms'],
        'pacu_beds': project['pacu_beds']
    }
    
    # ä¿å­˜æ¨¡æ¿
    cursor.execute('''
        INSERT INTO project_templates_custom (name, description, source_project_id, template_data, created_by)
        VALUES (?, ?, ?, ?, ?)
    ''', (
        data.get('name', f"{project['project_name']}_æ¨¡æ¿"),
        data.get('description', f"ä»é¡¹ç›®ã€Œ{project['project_name']}ã€åˆ›å»º"),
        project_id,
        json.dumps(template_data, ensure_ascii=False),
        session.get('username', 'system')
    ))
    conn.commit()
    template_id = cursor.lastrowid
    close_db()
    
    return api_response(True, {'id': template_id, 'message': 'æ¨¡æ¿ä¿å­˜æˆåŠŸ'})

@app.route('/api/templates/<int:template_id>', methods=['DELETE'])
def delete_template(template_id):
    """åˆ é™¤é¡¹ç›®æ¨¡æ¿"""
    conn = get_db()
    conn.execute('DELETE FROM project_templates_custom WHERE id = ?', (template_id,))
    conn.commit()
    close_db()
    return api_response(True, message='æ¨¡æ¿å·²åˆ é™¤')

# ========== å®¢æˆ·æ²Ÿé€šè®°å½• API ==========
@app.route('/api/projects/<int:project_id>/communications', methods=['GET'])
def get_project_communications(project_id):
    """è·å–é¡¹ç›®çš„æ²Ÿé€šè®°å½•"""
    conn = get_db()
    records = conn.execute('''
        SELECT * FROM customer_communications 
        WHERE project_id = ? ORDER BY contact_date DESC
    ''', (project_id,)).fetchall()
    close_db()
    return api_response(True, [dict(r) for r in records])

@app.route('/api/projects/<int:project_id>/communications', methods=['POST'])
def add_project_communication(project_id):
    """æ·»åŠ æ²Ÿé€šè®°å½•"""
    data = request.json
    conn = get_db()
    cursor = conn.cursor()
    cursor.execute('''
        INSERT INTO customer_communications 
        (project_id, contact_date, contact_person, contact_method, summary, related_issue_id, created_by)
        VALUES (?, ?, ?, ?, ?, ?, ?)
    ''', (
        project_id,
        data.get('contact_date'),
        data.get('contact_person'),
        data.get('contact_method'),
        data.get('summary'),
        data.get('related_issue_id'),
        data.get('created_by', 'system')
    ))
    conn.commit()
    record_id = cursor.lastrowid
    close_db()
    return api_response(True, {'id': record_id})

@app.route('/api/communications/<int:record_id>', methods=['DELETE'])
def delete_communication(record_id):
    """åˆ é™¤æ²Ÿé€šè®°å½•"""
    conn = get_db()
    conn.execute('DELETE FROM customer_communications WHERE id = ?', (record_id,))
    conn.commit()
    close_db()
    return api_response(True, message='è®°å½•å·²åˆ é™¤')

@app.route('/api/projects/<int:project_id>/communications/analyze', methods=['POST'])
def analyze_communications(project_id):
    """AIåˆ†æå®¢æˆ·æ²Ÿé€šè®°å½• - ä»é¡¹ç›®ç®¡ç†/éœ€æ±‚åˆ†æå¸ˆè§†è§’"""
    conn = get_db()
    
    project = conn.execute('SELECT * FROM projects WHERE id = ?', (project_id,)).fetchone()
    if not project:
        close_db()
        return jsonify({'error': 'é¡¹ç›®ä¸å­˜åœ¨'}), 404
    
    # è·å–æ‰€æœ‰æ²Ÿé€šè®°å½•
    records = conn.execute('''
        SELECT * FROM customer_communications 
        WHERE project_id = ? ORDER BY contact_date DESC
    ''', (project_id,)).fetchall()
    
    if not records:
        close_db()
        return jsonify({'error': 'æš‚æ— æ²Ÿé€šè®°å½•ï¼Œè¯·å…ˆæ·»åŠ æ²Ÿé€šè®°å½•å†è¿›è¡Œåˆ†æ'}), 400
    
    # è·å–é¡¹ç›®é˜¶æ®µå’Œè¿›åº¦
    stages = conn.execute(
        'SELECT stage_name, progress FROM project_stages WHERE project_id = ? ORDER BY stage_order',
        (project_id,)
    ).fetchall()
    
    # è·å–æ´»è·ƒé—®é¢˜
    issues = conn.execute(
        "SELECT description, severity, status FROM issues WHERE project_id = ? AND status != 'å·²è§£å†³'",
        (project_id,)
    ).fetchall()
    
    close_db()
    
    # æ„å»ºæ²Ÿé€šè®°å½•æ±‡æ€»
    comm_summary = "\n".join([
        f"- [{r['contact_date']}] å¯¹æ¥äºº:{r['contact_person']} | æ–¹å¼:{r['contact_method']} | å†…å®¹:{r['summary']}"
        for r in records
    ])
    
    stage_info = "\n".join([f"- {s['stage_name']}: {s['progress']}%" for s in stages]) if stages else "æ— é˜¶æ®µæ•°æ®"
    issue_info = "\n".join([f"- [{i['severity']}] {i['description']} ({i['status']})" for i in issues]) if issues else "æ— å¾…è§£å†³é—®é¢˜"
    
    prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„**åŒ»ç–—ä¿¡æ¯åŒ–é¡¹ç›®éœ€æ±‚åˆ†æå¸ˆå…¼é¡¹ç›®ç»ç†**ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„ICU/æ‰‹æœ¯å®¤ä¿¡æ¯ç³»ç»Ÿå®æ–½ç»éªŒã€‚

è¯·ä»ä¸“ä¸šè§’åº¦ï¼Œå¯¹ä»¥ä¸‹é¡¹ç›®çš„å®¢æˆ·æ²Ÿé€šè®°å½•è¿›è¡Œæ·±åº¦åˆ†æå’Œæç‚¼ã€‚

## é¡¹ç›®èƒŒæ™¯
- é¡¹ç›®åç§°: {project['project_name']}
- åŒ»é™¢: {project['hospital_name']}
- å½“å‰çŠ¶æ€: {project['status']}
- æ•´ä½“è¿›åº¦: {project['progress']}%

## å½“å‰é˜¶æ®µè¿›åº¦
{stage_info}

## å¾…è§£å†³é—®é¢˜
{issue_info}

## å®¢æˆ·æ²Ÿé€šè®°å½•ï¼ˆæŒ‰æ—¶é—´å€’åºï¼‰
{comm_summary}

---

è¯·æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºåˆ†ææŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰:

## ğŸ“Š æ²Ÿé€šè¦ç‚¹æç‚¼
æç‚¼å‡ºå®¢æˆ·æ ¸å¿ƒè¯‰æ±‚å’Œå…³é”®ä¿¡æ¯ç‚¹ã€‚

## ğŸ” éœ€æ±‚åˆç†æ€§åˆ†æ
é€ä¸€åˆ†æå®¢æˆ·æå‡ºçš„éœ€æ±‚æ˜¯å¦åˆç†ï¼ˆæŠ€æœ¯å¯è¡Œæ€§ã€èŒƒå›´æ˜¯å¦è¶…å‡ºã€å®æ–½éš¾åº¦ï¼‰ï¼Œæ ‡æ³¨ã€åˆç†ã€‘ã€éœ€è®¨è®ºã€‘ã€ä¸åˆç†ã€‘ã€‚

## âš ï¸ é£é™©ä¸éšæ‚£
ä»æ²Ÿé€šè®°å½•ä¸­å‘ç°çš„æ½œåœ¨é£é™©å’Œéœ€è¦å…³æ³¨çš„é—®é¢˜ã€‚

## ğŸ“‹ ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’
å…·ä½“çš„ã€å¯æ‰§è¡Œçš„ä¸‹ä¸€æ­¥å·¥ä½œå»ºè®®ï¼ŒåŒ…æ‹¬ï¼š
- éœ€è¦å›å¤å®¢æˆ·çš„äº‹é¡¹
- éœ€è¦å†…éƒ¨åè°ƒçš„äº‹é¡¹
- éœ€è¦æŠ€æœ¯éªŒè¯çš„äº‹é¡¹

## ğŸ’¡ ä¸“ä¸šå»ºè®®
ä»é¡¹ç›®ç®¡ç†æœ€ä½³å®è·µè§’åº¦ç»™å‡ºçš„å»ºè®®ï¼Œå¸®åŠ©é¡¹ç›®å›¢é˜Ÿæ›´å¥½åœ°æ¨è¿›ã€‚

æ³¨æ„ï¼šåˆ†æè¦åˆ‡ä¸­è¦ç‚¹ã€æœ‰æ´å¯ŸåŠ›ï¼Œç»™å‡ºæœ‰å®é™…æŒ‡å¯¼ä»·å€¼çš„å»ºè®®ï¼Œè€Œä¸æ˜¯ç©ºæ³›çš„æ¦‚è¿°ã€‚
"""
    
    try:
        from ai_utils import call_ai
        analysis = call_ai(prompt, task_type='analysis')
        return jsonify({'analysis': analysis})
    except Exception as e:
        return jsonify({'error': f'AIåˆ†æå¤±è´¥: {str(e)}'}), 500

@app.route('/api/projects/<int:project_id>/communications/analyze-file', methods=['POST'])
def analyze_communication_file(project_id):
    """ä¸Šä¼ æ–‡ä»¶å¹¶è¿›è¡ŒAIåˆ†æ - ä»é¡¹ç›®ç®¡ç†/éœ€æ±‚åˆ†æå¸ˆè§†è§’"""
    if 'file' not in request.files:
        return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400

    from services.file_parser import is_supported, extract_text_from_file
    if not is_supported(file.filename):
        return jsonify({'error': f'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚æ”¯æŒ: Word(.docx), PDF, Excel(.xlsx), TXT, CSV, Markdown'}), 400

    # ä¿å­˜æ–‡ä»¶
    import os
    upload_dir = os.path.join(os.path.dirname(__file__), 'uploads', 'comm_files')
    os.makedirs(upload_dir, exist_ok=True)

    import time
    # ä¿ç•™åŸå§‹æ‰©å±•åï¼ˆsecure_filename ä¼šå»æ‰ä¸­æ–‡å¯¼è‡´ä¸¢å¤±æ‰©å±•åï¼‰
    ext = os.path.splitext(file.filename)[1].lower()
    safe_name = f"{int(time.time())}_upload{ext}"
    filepath = os.path.join(upload_dir, safe_name)
    file.save(filepath)

    # æå–æ–‡æœ¬
    file_text = extract_text_from_file(filepath)
    if file_text.startswith('[') and file_text.endswith(']'):
        return jsonify({'error': file_text}), 400

    # æˆªå–å‰ 8000 å­—ç¬¦é¿å…è¶…å‡º AI token é™åˆ¶
    if len(file_text) > 8000:
        file_text = file_text[:8000] + f"\n\n... [æ–‡ä»¶å†…å®¹è¿‡é•¿ï¼Œå·²æˆªå–å‰ 8000 å­—ç¬¦ï¼ŒåŸæ–‡å…± {len(file_text)} å­—ç¬¦]"

    # è·å–é¡¹ç›®ä¸Šä¸‹æ–‡
    conn = get_db()
    project = conn.execute('SELECT * FROM projects WHERE id = ?', (project_id,)).fetchone()
    if not project:
        close_db()
        return jsonify({'error': 'é¡¹ç›®ä¸å­˜åœ¨'}), 404

    stages = conn.execute(
        'SELECT stage_name, progress FROM project_stages WHERE project_id = ? ORDER BY stage_order',
        (project_id,)
    ).fetchall()
    issues = conn.execute(
        "SELECT description, severity, status FROM issues WHERE project_id = ? AND status != 'å·²è§£å†³'",
        (project_id,)
    ).fetchall()
    close_db()

    stage_info = "\n".join([f"- {s['stage_name']}: {s['progress']}%" for s in stages]) if stages else "æ— é˜¶æ®µæ•°æ®"
    issue_info = "\n".join([f"- [{i['severity']}] {i['description']} ({i['status']})" for i in issues]) if issues else "æ— å¾…è§£å†³é—®é¢˜"

    prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„**åŒ»ç–—ä¿¡æ¯åŒ–é¡¹ç›®éœ€æ±‚åˆ†æå¸ˆå…¼é¡¹ç›®ç»ç†**ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„ICU/æ‰‹æœ¯å®¤ä¿¡æ¯ç³»ç»Ÿå®æ–½ç»éªŒã€‚

è¯·å¯¹ä¸Šä¼ çš„å®¢æˆ·æ²Ÿé€šæ–‡ä»¶è¿›è¡Œæ·±åº¦åˆ†æã€‚æ–‡ä»¶å: {file.filename}

## é¡¹ç›®èƒŒæ™¯
- é¡¹ç›®åç§°: {project['project_name']}
- åŒ»é™¢: {project['hospital_name']}
- å½“å‰çŠ¶æ€: {project['status']}
- æ•´ä½“è¿›åº¦: {project['progress']}%

## å½“å‰é˜¶æ®µè¿›åº¦
{stage_info}

## å¾…è§£å†³é—®é¢˜
{issue_info}

## ä¸Šä¼ æ–‡ä»¶å†…å®¹
{file_text}

---

è¯·æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºåˆ†ææŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰:

### ğŸ“„ æ–‡ä»¶æ¦‚è¦
æ¦‚æ‹¬æ–‡ä»¶ä¸»è¦å†…å®¹å’Œç±»å‹ï¼ˆä¼šè®®çºªè¦/é‚®ä»¶/éœ€æ±‚ç¡®è®¤å•ç­‰ï¼‰ã€‚

### ğŸ“Š å…³é”®ä¿¡æ¯æå–
ä»æ–‡ä»¶ä¸­æå–å‡ºæ‰€æœ‰é‡è¦çš„å†³ç­–ã€æ‰¿è¯ºã€éœ€æ±‚ç‚¹å’Œæ—¶é—´èŠ‚ç‚¹ã€‚

### ğŸ” éœ€æ±‚åˆç†æ€§è¯„ä¼°
é€ä¸€åˆ†ææ–‡ä»¶ä¸­æå‡ºçš„éœ€æ±‚/è¦æ±‚æ˜¯å¦åˆç†ï¼Œæ ‡æ³¨ã€åˆç†ã€‘ã€éœ€è®¨è®ºã€‘ã€ä¸åˆç†ã€‘ã€‚

### âš ï¸ é£é™©è¯†åˆ«
ä»è¯¥æ–‡ä»¶å†…å®¹ä¸­å‘ç°çš„æ½œåœ¨é£é™©ã€‚

### ğŸ“‹ è¡ŒåŠ¨é¡¹ï¼ˆTo-Doï¼‰
ä»æ–‡ä»¶ä¸­æå–å‡ºå…·ä½“çš„å¯æ‰§è¡Œå¾…åŠäº‹é¡¹ï¼Œæ ‡æ³¨è´£ä»»æ–¹ï¼ˆæˆ‘æ–¹/ç”²æ–¹ï¼‰å’Œå»ºè®®å®Œæˆæ—¶é—´ã€‚

### ğŸ’¡ ç­–ç•¥å»ºè®®
ä»é¡¹ç›®ç®¡ç†è§’åº¦ç»™å‡ºåº”å¯¹ç­–ç•¥å’Œå»ºè®®ã€‚

æ³¨æ„ï¼šåˆ†æè¦åˆ‡ä¸­è¦ç‚¹ã€å…·ä½“åˆ°ä½ï¼Œä¸è¦ç©ºæ³›åœ°å¤è¿°æ–‡ä»¶å†…å®¹ã€‚
"""

    try:
        from ai_utils import call_ai
        analysis = call_ai(prompt, task_type='analysis')
        return jsonify({'analysis': analysis, 'filename': file.filename, 'text_length': len(file_text)})
    except Exception as e:
        return jsonify({'error': f'AIåˆ†æå¤±è´¥: {str(e)}'}), 500

# ========== AIé¡¹ç›®å¤ç›˜ API ==========
@app.route('/api/projects/<int:project_id>/ai-retrospective', methods=['POST'])
def ai_project_retrospective(project_id):
    """AIç”Ÿæˆé¡¹ç›®å¤ç›˜æŠ¥å‘Š"""
    try:
        from ai_utils import call_ai
        
        conn = get_db()
        # è·å–é¡¹ç›®ä¿¡æ¯
        project = conn.execute('SELECT * FROM projects WHERE id = ?', (project_id,)).fetchone()
        if not project:
            close_db()
            return api_response(False, message='é¡¹ç›®ä¸å­˜åœ¨', code=404)
        
        # è·å–é¡¹ç›®ç»Ÿè®¡
        stages = conn.execute('SELECT * FROM project_stages WHERE project_id = ?', (project_id,)).fetchall()
        tasks = conn.execute('''
            SELECT t.* FROM tasks t 
            JOIN project_stages s ON t.stage_id = s.id 
            WHERE s.project_id = ?
        ''', (project_id,)).fetchall()
        issues = conn.execute('SELECT * FROM issues WHERE project_id = ?', (project_id,)).fetchall()
        logs = conn.execute('SELECT * FROM work_logs WHERE project_id = ? ORDER BY log_date DESC LIMIT 50', (project_id,)).fetchall()
        close_db()
        
        # æ„å»ºprompt
        completed_tasks = sum(1 for t in tasks if t['status'] == 'å·²å®Œæˆ')
        open_issues = sum(1 for i in issues if i['status'] not in ['å·²è§£å†³', 'å·²å…³é—­'])
        
        prompt = f"""ä½œä¸ºé¡¹ç›®ç®¡ç†ä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹å·²å®Œæˆçš„ICU/éº»é†‰ç³»ç»Ÿå®æ–½é¡¹ç›®è¿›è¡Œå¤ç›˜åˆ†æï¼Œç”Ÿæˆä¸€ä»½ç®€æ´çš„å¤ç›˜æŠ¥å‘Šã€‚

## é¡¹ç›®ä¿¡æ¯
- é¡¹ç›®åç§°ï¼š{project['project_name']}
- åŒ»é™¢ï¼š{project['hospital_name']}
- é¡¹ç›®ç»ç†ï¼š{project['project_manager']}
- çŠ¶æ€ï¼š{project['status']}
- è¿›åº¦ï¼š{project['progress']}%
- è®¡åˆ’å‘¨æœŸï¼š{project['plan_start_date']} ~ {project['plan_end_date']}
- å®é™…å®Œæˆï¼š{project.get('actual_end_date', 'æœªè®°å½•')}

## é¡¹ç›®ç»Ÿè®¡
- é˜¶æ®µæ•°ï¼š{len(stages)}
- ä»»åŠ¡å®Œæˆç‡ï¼š{completed_tasks}/{len(tasks)}
- é—ç•™é—®é¢˜ï¼š{open_issues}
- å·¥ä½œæ—¥å¿—ï¼š{len(logs)}æ¡

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºå¤ç›˜æŠ¥å‘Šï¼ˆä½¿ç”¨Markdownï¼‰ï¼š
## ğŸ¯ é¡¹ç›®æ€»ç»“
ä¸€å¥è¯æ€»ç»“é¡¹ç›®æ•´ä½“è¡¨ç°

## âœ… åšå¾—å¥½çš„åœ°æ–¹
- åˆ—å‡º3ä¸ªäº®ç‚¹

## âš ï¸ éœ€è¦æ”¹è¿›çš„åœ°æ–¹
- åˆ—å‡º3ä¸ªæ”¹è¿›ç‚¹

## ğŸ“š ç»éªŒæ•™è®­
- åˆ—å‡º3æ¡å…³é”®ç»éªŒ

## ğŸ’¡ å»ºè®®
ç»™æœªæ¥ç±»ä¼¼é¡¹ç›®çš„å»ºè®®
"""
        
        result = call_ai(prompt, task_type='summary')
        return api_response(True, {'report': result})
    except Exception as e:
        return api_response(False, message=str(e), code=500)

# ========== AIä»»åŠ¡åˆ†é…å»ºè®® API ==========
@app.route('/api/projects/<int:project_id>/ai-task-suggestions', methods=['POST'])
def ai_task_suggestions(project_id):
    """AIç”Ÿæˆä»»åŠ¡åˆ†é…å»ºè®®"""
    try:
        from ai_utils import call_ai
        
        conn = get_db()
        # è·å–é¡¹ç›®ä¿¡æ¯
        project = conn.execute('SELECT * FROM projects WHERE id = ?', (project_id,)).fetchone()
        if not project:
            close_db()
            return api_response(False, message='é¡¹ç›®ä¸å­˜åœ¨', code=404)
        
        # è·å–æœªåˆ†é…ä»»åŠ¡ (ç”±äºschemaä¸­æ²¡æœ‰assigned_toï¼Œç›®å‰è®¤ä¸ºæœªå®Œæˆçš„ä»»åŠ¡å³ä¸ºå¾…åˆ†é…ä»»åŠ¡)
        tasks = conn.execute('''
            SELECT t.id, t.task_name, t.is_completed, s.stage_name
            FROM tasks t 
            JOIN project_stages s ON t.stage_id = s.id 
            WHERE s.project_id = ? AND t.is_completed = 0
        ''', (project_id,)).fetchall()
        
        # è·å–å›¢é˜Ÿæˆå‘˜
        members = conn.execute('''
            SELECT * FROM project_members 
            WHERE project_id = ? AND status = 'åœ¨å²—'
        ''', (project_id,)).fetchall()
        close_db()
        
        if not tasks:
            return api_response(True, {'suggestions': [], 'message': 'æš‚æ— æœªåˆ†é…ä»»åŠ¡'})
        
        if not members:
            return api_response(True, {'suggestions': [], 'message': 'æš‚æ— å›¢é˜Ÿæˆå‘˜'})
        
        # æ„å»ºprompt
        tasks_info = "\n".join([f"- [{t['id']}] {t['stage_name']}: {t['task_name']}" for t in tasks[:15]])
        members_info = "\n".join([f"- {m['name']} ({m['role']})" for m in members])
        
        prompt = f"""ä½œä¸ºé¡¹ç›®ç®¡ç†ä¸“å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç»™å‡ºä»»åŠ¡åˆ†é…å»ºè®®ã€‚

## æœªåˆ†é…ä»»åŠ¡
{tasks_info}

## å›¢é˜Ÿæˆå‘˜
{members_info}

è¯·æŒ‰JSONæ ¼å¼è¿”å›åˆ†é…å»ºè®®ï¼š
[
  {{"task_id": ä»»åŠ¡ID, "task_name": "ä»»åŠ¡å", "suggested_member": "å»ºè®®åˆ†é…äºº", "reason": "åˆ†é…åŸå› "}}
]

åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦å…¶ä»–è¯´æ˜æ–‡å­—ã€‚"""
        
        result = call_ai(prompt, task_type='analysis')
        
        # å°è¯•è§£æJSON
        import json
        try:
            # æå–JSONéƒ¨åˆ†
            json_start = result.find('[')
            json_end = result.rfind(']') + 1
            if json_start >= 0 and json_end > json_start:
                suggestions = json.loads(result[json_start:json_end])
                return api_response(True, {'suggestions': suggestions})
        except:
            pass
        
        return api_response(True, {'suggestions': [], 'raw_response': result})
    except Exception as e:
        return api_response(False, message=str(e), code=500)

# ========== ä»»åŠ¡ä¾èµ–å…³ç³» API ==========
@app.route('/api/projects/<int:project_id>/dependencies', methods=['GET'])
def get_project_dependencies(project_id):
    """è·å–é¡¹ç›®æ‰€æœ‰ä»»åŠ¡ä¾èµ–å…³ç³»"""
    from services.dependency_service import dependency_service
    deps = dependency_service.get_dependencies(project_id)
    return api_response(True, deps)

@app.route('/api/dependencies', methods=['POST'])
def add_task_dependency():
    """æ·»åŠ ä»»åŠ¡ä¾èµ–"""
    from services.dependency_service import dependency_service
    data = request.json
    result = dependency_service.add_dependency(
        data['task_id'], data['depends_on_task_id'],
        data.get('dependency_type', 'finish_to_start')
    )
    if result['success']:
        return api_response(True, message=result['message'])
    return api_response(False, message=result['message'], code=400)

@app.route('/api/dependencies/<int:dep_id>', methods=['DELETE'])
def delete_task_dependency(dep_id):
    """åˆ é™¤ä»»åŠ¡ä¾èµ–"""
    from services.dependency_service import dependency_service
    dependency_service.remove_dependency(dep_id)
    return api_response(True, message='ä¾èµ–å…³ç³»å·²åˆ é™¤')

@app.route('/api/projects/<int:project_id>/critical-path', methods=['GET'])
def get_critical_path(project_id):
    """è·å–é¡¹ç›®å…³é”®è·¯å¾„"""
    from services.dependency_service import dependency_service
    result = dependency_service.get_critical_path(project_id)
    return api_response(True, result)

@app.route('/api/tasks/<int:task_id>/impact', methods=['GET'])
def get_task_impact(task_id):
    """è·å–ä»»åŠ¡å»¶è¿Ÿå½±å“åˆ†æ"""
    from services.dependency_service import dependency_service
    result = dependency_service.get_impact_analysis(task_id)
    return api_response(True, result)

@app.route('/api/tasks/<int:task_id>/available-dependencies', methods=['GET'])
def get_available_deps(task_id):
    """è·å–å¯ç”¨çš„ä¾èµ–ä»»åŠ¡åˆ—è¡¨"""
    from services.dependency_service import dependency_service
    result = dependency_service.get_available_dependencies(task_id)
    return api_response(True, result)

# ========== æ¯æ—¥ç«™ä¼šåŠ©æ‰‹ API ==========
@app.route('/api/projects/<int:project_id>/standup', methods=['GET'])
def get_standup_data(project_id):
    """è·å–ç«™ä¼šèšåˆæ•°æ®"""
    from services.standup_service import standup_service
    date_str = request.args.get('date')
    data = standup_service.get_standup_data(project_id, date_str)
    if data:
        return api_response(True, data)
    return api_response(False, message='é¡¹ç›®ä¸å­˜åœ¨', code=404)

@app.route('/api/projects/<int:project_id>/standup/generate', methods=['POST'])
def generate_standup(project_id):
    """AIç”Ÿæˆç«™ä¼šçºªè¦"""
    from services.standup_service import standup_service
    date_str = request.json.get('date') if request.json else None
    result = standup_service.generate_ai_standup(project_id, date_str)

    # ä¿å­˜åˆ°æ•°æ®åº“
    if result.get('standup'):
        conn = get_db()
        today = date_str or datetime.now().strftime('%Y-%m-%d')
        conn.execute('''
            INSERT OR REPLACE INTO standup_minutes (project_id, meeting_date, content, ai_generated, created_by)
            VALUES (?, ?, ?, 1, 'AI')
        ''', (project_id, today, result['standup']))
        conn.commit()
        close_db()

    return api_response(True, result)

@app.route('/api/standup/briefing', methods=['GET'])
def get_daily_briefing():
    """è·å–å…¨å±€æ¯æ—¥ç®€æŠ¥"""
    from services.standup_service import standup_service
    result = standup_service.generate_daily_briefing()
    return api_response(True, result)

@app.route('/api/standup/push-wecom', methods=['POST'])
def push_briefing_wecom():
    """æ¨é€æ¯æ—¥ç®€æŠ¥åˆ°ä¼ä¸šå¾®ä¿¡"""
    from services.standup_service import standup_service
    result = standup_service.push_briefing_to_wecom()
    return api_response(result['success'], message=result['message'])

@app.route('/api/projects/<int:project_id>/standup/history', methods=['GET'])
def get_standup_history(project_id):
    """è·å–ç«™ä¼šçºªè¦å†å²"""
    conn = get_db()
    records = conn.execute('''
        SELECT * FROM standup_minutes
        WHERE project_id = ?
        ORDER BY meeting_date DESC
        LIMIT 30
    ''', (project_id,)).fetchall()
    close_db()
    return api_response(True, [dict(r) for r in records])

# ========== è¿›åº¦å¿«ç…§ä¸åå·®åˆ†æ API ==========
@app.route('/api/projects/<int:project_id>/snapshots', methods=['GET'])
def get_project_snapshots(project_id):
    """è·å–é¡¹ç›®è¿›åº¦å¿«ç…§åˆ—è¡¨"""
    from services.snapshot_service import snapshot_service
    weeks = request.args.get('weeks', 8, type=int)
    snapshots = snapshot_service.get_snapshots(project_id, weeks)
    return api_response(True, snapshots)

@app.route('/api/projects/<int:project_id>/snapshots', methods=['POST'])
def capture_project_snapshot(project_id):
    """æ‰‹åŠ¨æ‹æ‘„è¿›åº¦å¿«ç…§"""
    from services.snapshot_service import snapshot_service
    result = snapshot_service.capture_snapshot(project_id, 'manual')
    if result:
        return api_response(True, result, message='å¿«ç…§å·²ä¿å­˜')
    return api_response(False, message='é¡¹ç›®ä¸å­˜åœ¨', code=404)

@app.route('/api/snapshots/capture-all', methods=['POST'])
def capture_all_snapshots():
    """ä¸ºæ‰€æœ‰æ´»è·ƒé¡¹ç›®æ‹æ‘„å¿«ç…§"""
    from services.snapshot_service import snapshot_service
    results = snapshot_service.capture_all_snapshots()
    return api_response(True, results, message=f'å·²ä¸º {len(results)} ä¸ªé¡¹ç›®æ‹æ‘„å¿«ç…§')

@app.route('/api/projects/<int:project_id>/deviation', methods=['GET'])
def get_deviation_analysis(project_id):
    """è·å–è¿›åº¦åå·®åˆ†æ"""
    from services.snapshot_service import snapshot_service
    result = snapshot_service.get_deviation_analysis(project_id)
    return api_response(True, result)

@app.route('/api/projects/<int:project_id>/deviation/ai-report', methods=['POST'])
def generate_deviation_report(project_id):
    """AIç”Ÿæˆåå·®åˆ†ææŠ¥å‘Š"""
    from services.snapshot_service import snapshot_service
    result = snapshot_service.generate_ai_deviation_report(project_id)
    return api_response(True, result)

# ========== åŒ»é™¢åç§°åˆ—è¡¨ API ==========
@app.route('/api/hospitals', methods=['GET'])
def get_hospitals():
    conn = get_db()
    hospitals = conn.execute('SELECT DISTINCT hospital_name FROM projects ORDER BY hospital_name').fetchall()
    # Connection closed by teardown
    return api_response(True, [h['hospital_name'] for h in hospitals])

# ========== æ™ºèƒ½æé†’ API ==========
@app.route('/api/reminders', methods=['GET'])
def get_reminders():
    """è·å–æ‰€æœ‰ç±»å‹çš„æé†’"""
    try:
        from services.reminder_service import reminder_service
        reminders = reminder_service.get_all_reminders()
        return api_response(True, reminders)
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/reminders/digest', methods=['GET'])
def get_reminder_digest():
    """è·å–æ¯æ—¥æ‘˜è¦"""
    try:
        from services.reminder_service import reminder_service
        digest = reminder_service.get_daily_digest()
        return api_response(True, digest)
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/reminders/overdue', methods=['GET'])
def get_overdue_reminders():
    """è·å–é€¾æœŸé¡¹"""
    try:
        from services.reminder_service import reminder_service
        overdue = reminder_service.check_overdue_milestones()
        return api_response(True, {'overdue_milestones': overdue})
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/reminders/upcoming', methods=['GET'])
def get_upcoming_reminders():
    """è·å–å³å°†åˆ°æœŸé¡¹"""
    try:
        from services.reminder_service import reminder_service
        days = request.args.get('days', 7, type=int)
        upcoming = reminder_service.check_upcoming_deadlines(days)
        return api_response(True, {'upcoming_deadlines': upcoming})
    except Exception as e:
        return api_response(False, message=str(e), code=500)

# Legacy template API removed in favor of database-backed implementation


# ========== ç”¨æˆ·è®¤è¯ API ==========
@app.route('/api/auth/login', methods=['POST'])
def user_login():
    """ç”¨æˆ·ç™»å½•"""
    try:
        from services.auth_service import auth_service
        data = request.json
        username = data.get('username')
        password = data.get('password')
        if not username or not password:
            return api_response(False, message="ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º", code=400)
        result = auth_service.login(username, password)
        if result['success']:
            # è®¾ç½® Cookie
            response = make_response(api_response(True, data=result.get('user'), message="ç™»å½•æˆåŠŸ"))
            response.set_cookie('auth_token', result['token'], httponly=True, max_age=86400)
            return response
        return api_response(False, message=result.get('message', 'ç™»å½•å¤±è´¥'))
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/auth/register', methods=['POST'])
def user_register():
    """ç”¨æˆ·æ³¨å†Œ"""
    try:
        from services.auth_service import auth_service
        data = request.json
        result = auth_service.register(
            username=data.get('username'),
            password=data.get('password'),
            email=data.get('email'),
            display_name=data.get('display_name'),
            role=data.get('role', 'team_member')
        )
        return api_response(result['success'], message=result['message'])
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/auth/me', methods=['GET'])
def get_current_user():
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    try:
        from services.auth_service import auth_service
        token = request.headers.get('Authorization', '').replace('Bearer ', '')
        if not token:
            token = request.cookies.get('auth_token')
        user = auth_service.validate_token(token)
        if user:
            return api_response(True, user)
        return api_response(False, message="æœªç™»å½•", code=401)
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/auth/logout', methods=['POST'])
def user_logout():
    """ç”¨æˆ·ç™»å‡º"""
    try:
        from services.auth_service import auth_service
        # ä» Cookie æˆ– Header è·å– token
        token = request.headers.get('Authorization', '').replace('Bearer ', '')
        if not token:
            token = request.cookies.get('auth_token')
        if token:
            auth_service.logout(token)
        # æ¸…é™¤ Cookie
        response = make_response(api_response(True, message="å·²ç™»å‡º"))
        response.delete_cookie('auth_token')
        return response
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/users', methods=['GET'])
def get_users():
    """è·å–ç”¨æˆ·åˆ—è¡¨ï¼ˆç®¡ç†å‘˜ï¼‰"""
    try:
        from services.auth_service import auth_service
        users = auth_service.get_all_users()
        return api_response(True, users)
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/auth/migrate', methods=['POST'])
def migrate_auth_data():
    """æ•°æ®è¿ç§»ï¼šå°†ç°æœ‰é¡¹ç›®åˆ†é…ç»™ç®¡ç†å‘˜"""
    try:
        from services.auth_service import auth_service
        token = request.headers.get('Authorization', '').replace('Bearer ', '')
        if not token:
            token = request.cookies.get('auth_token')
        current_user = auth_service.validate_token(token)
        
        if not current_user or current_user['role'] != 'admin':
            return api_response(False, message="ä»…ç®¡ç†å‘˜å¯æ“ä½œ", code=403)
            
        result = auth_service.migrate_existing_projects()
        return api_response(result['success'], message=result['message'])
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/users/<int:user_id>/status', methods=['POST'])
def update_user_status(user_id):
    """æ›´æ–°ç”¨æˆ·çŠ¶æ€ï¼ˆä»…ç®¡ç†å‘˜ï¼‰"""
    try:
        from services.auth_service import auth_service
        # éªŒè¯æƒé™
        token = request.headers.get('Authorization', '').replace('Bearer ', '')
        if not token:
            token = request.cookies.get('auth_token')
        current_user = auth_service.validate_token(token)
        
        if not current_user or current_user['role'] != 'admin':
            return api_response(False, message="ä»…ç®¡ç†å‘˜å¯æ“ä½œ", code=403)
            
        data = request.json
        is_active = data.get('is_active', True)
        
        # é˜²æ­¢ç¦ç”¨è‡ªå·±
        if user_id == current_user['id'] and not is_active:
             return api_response(False, message="ä¸èƒ½ç¦ç”¨å½“å‰ç™»å½•è´¦å·", code=400)

        result = auth_service.update_user_status(user_id, is_active)
        return api_response(result['success'], message=result.get('message'))
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/users/<int:user_id>/password', methods=['POST'])
def reset_user_password(user_id):
    """é‡ç½®ç”¨æˆ·å¯†ç ï¼ˆä»…ç®¡ç†å‘˜ï¼‰"""
    try:
        from services.auth_service import auth_service
        # éªŒè¯æƒé™
        token = request.headers.get('Authorization', '').replace('Bearer ', '')
        if not token:
            token = request.cookies.get('auth_token')
        current_user = auth_service.validate_token(token)
        
        if not current_user or current_user['role'] != 'admin':
            return api_response(False, message="ä»…ç®¡ç†å‘˜å¯æ“ä½œ", code=403)
            
        data = request.json
        new_password = data.get('password')
        if not new_password:
             return api_response(False, message="æ–°å¯†ç ä¸èƒ½ä¸ºç©º", code=400)

        result = auth_service.reset_user_password(user_id, new_password)
        return api_response(result['success'], message=result.get('message'))
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/projects/<int:project_id>/access', methods=['GET'])
def get_project_access(project_id):
    """è·å–æœ‰æƒè®¿é—®è¯¥é¡¹ç›®çš„ç”¨æˆ·åˆ—è¡¨"""
    try:
        from services.auth_service import auth_service
        members = auth_service.get_project_members(project_id)
        return api_response(True, members)
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/projects/<int:project_id>/access', methods=['POST'])
def add_project_access(project_id):
    """æˆæƒç”¨æˆ·è®¿é—®é¡¹ç›®"""
    try:
        from services.auth_service import auth_service
        data = request.json
        user_id = data.get('user_id')
        role = data.get('role', 'member')
        if not user_id:
            return api_response(False, message="ç¼ºå°‘ç”¨æˆ·ID", code=400)
            
        result = auth_service.add_project_member(project_id, user_id, role)
        return api_response(result['success'], message=result.get('message'))
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/projects/<int:project_id>/access/<int:user_id>', methods=['DELETE'])
def remove_project_access(project_id, user_id):
    """ç§»é™¤ç”¨æˆ·å¯¹é¡¹ç›®çš„è®¿é—®æƒé™"""
    try:
        from services.auth_service import auth_service
        result = auth_service.remove_project_member(project_id, user_id)
        return api_response(result['success'], message=result.get('message'))
    except Exception as e:
        return api_response(False, message=str(e), code=500)

# ========== æ•°æ®åˆ†æ API ==========
@app.route('/api/analytics/compare', methods=['POST'])
def compare_projects():
    """é¡¹ç›®å¯¹æ¯”åˆ†æ"""
    try:
        from services.analytics_service import analytics_service
        data = request.json
        project_ids = data.get('project_ids', [])
        result = analytics_service.compare_projects(project_ids)
        return api_response(True, result)
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/analytics/trends', methods=['GET'])
def get_trend_analysis():
    """è·å–è¶‹åŠ¿åˆ†æ"""
    try:
        from services.analytics_service import analytics_service
        project_id = request.args.get('project_id', type=int)
        days = request.args.get('days', 30, type=int)
        result = analytics_service.get_trend_data(project_id, days)
        return api_response(True, result)
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/analytics/health/<int:project_id>', methods=['GET'])
def get_project_health(project_id):
    """è·å–é¡¹ç›®å¥åº·åº¦è¯„åˆ†"""
    try:
        from services.analytics_service import analytics_service
        result = analytics_service.get_project_health_score(project_id)
        return api_response(True, result)
    except Exception as e:
        return api_response(False, message=str(e), code=500)

# ========== AI å¢å¼º API ==========
@app.route('/api/ai/query', methods=['POST'])
def ai_natural_query():
    """AI è‡ªç„¶è¯­è¨€æŸ¥è¯¢"""
    try:
        data = request.json
        query = data.get('query', '')
        if not query:
            return api_response(False, message="æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º", code=400)
        
        # æ„å»ºæŸ¥è¯¢ä¸Šä¸‹æ–‡
        conn = get_db()
        projects = conn.execute('''
            SELECT id, project_name, hospital_name, status, progress, project_manager 
            FROM projects WHERE status NOT IN ('å·²å®Œæˆ', 'å·²ç»ˆæ­¢')
        ''').fetchall()
        
        context = "å½“å‰æ´»è·ƒé¡¹ç›®åˆ—è¡¨:\n"
        for p in projects:
            context += f"- {p['project_name']} ({p['hospital_name']}): çŠ¶æ€={p['status']}, è¿›åº¦={p['progress']}%, è´Ÿè´£äºº={p['project_manager'] or 'æœªæŒ‡å®š'}\n"
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªé¡¹ç›®ç®¡ç†åŠ©æ‰‹ã€‚ç”¨æˆ·ä¼šç”¨è‡ªç„¶è¯­è¨€è¯¢é—®é¡¹ç›®ç›¸å…³é—®é¢˜ã€‚
è¯·æ ¹æ®æä¾›çš„é¡¹ç›®æ•°æ®ï¼Œç”¨ç®€æ´ä¸­æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
å¦‚æœç”¨æˆ·è¦æ±‚ç­›é€‰æˆ–ç»Ÿè®¡ï¼Œè¯·ç»™å‡ºç»“æœåˆ—è¡¨ã€‚
å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯´æ˜éœ€è¦å“ªäº›ä¿¡æ¯ã€‚"""
        
        user_prompt = f"é¡¹ç›®æ•°æ®:\n{context}\n\nç”¨æˆ·é—®é¢˜: {query}"
        
        response = call_deepseek_api(system_prompt, user_prompt, task_type="chat")
        return api_response(True, {"query": query, "answer": response})
    except Exception as e:
        return api_response(False, message=str(e), code=500)

@app.route('/api/ai/classify-issue', methods=['POST'])
def ai_classify_issue():
    """AI é—®é¢˜è‡ªåŠ¨åˆ†ç±»"""
    try:
        data = request.json
        description = data.get('description', '')
        if not description:
            return api_response(False, message="é—®é¢˜æè¿°ä¸èƒ½ä¸ºç©º", code=400)
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªICUä¿¡æ¯åŒ–é¡¹ç›®çš„é—®é¢˜åˆ†ç±»åŠ©æ‰‹ã€‚
è¯·æ ¹æ®é—®é¢˜æè¿°ï¼Œåˆ¤æ–­ï¼š
1. é—®é¢˜ç±»å‹ (æŠ€æœ¯é—®é¢˜/éœ€æ±‚å˜æ›´/æ¥å£é—®é¢˜/è®¾å¤‡é—®é¢˜/åŸ¹è®­é—®é¢˜/åè°ƒé—®é¢˜/å…¶ä»–)
2. å»ºè®®çš„ä¸¥é‡ç¨‹åº¦ (é«˜/ä¸­/ä½)
3. å¤„ç†ä¼˜å…ˆçº§å»ºè®®

è¯·ç”¨JSONæ ¼å¼è¿”å›ï¼š{"type": "ç±»å‹", "severity": "ä¸¥é‡ç¨‹åº¦", "priority": "ä¼˜å…ˆçº§è¯´æ˜", "suggestion": "å¤„ç†å»ºè®®"}"""
        
        response = call_deepseek_api(system_prompt, description, task_type="analysis")
        
        # å°è¯•è§£æJSON
        try:
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
            else:
                result = {"raw_response": response}
        except:
            result = {"raw_response": response}
        
        return api_response(True, result)
    except Exception as e:
        return api_response(False, message=str(e), code=500)


# ========== é¡¹ç›®çŠ¶æ€é…ç½® API ==========
@app.route('/api/project-status-config', methods=['GET'])
def get_project_status_config():
    return jsonify(PROJECT_STATUS)


# ========== Notifications - Migrated to monitor_service ==========

# ========== AI æ ¸å¿ƒé€»è¾‘ ==========
def call_deepseek_api(system_prompt, user_content, task_type="analysis"):
    """
    è°ƒç”¨AI APIï¼Œæ”¯æŒå¤šç«¯ç‚¹æ™ºèƒ½è‡ªåŠ¨å›é€€å’Œå¥åº·ç›‘æµ‹
    åŸºäº ai_config.ai_manager çš„å…¨å±€åºåˆ—è¿›è¡Œè°ƒåº¦
    """
    from ai_config import ai_manager, TaskType
    
    # è½¬æ¢ä»»åŠ¡ç±»å‹ä¸ºæšä¸¾
    task_enum = TaskType.ANALYSIS
    for t in TaskType:
        if t.value == task_type:
            task_enum = t
            break
            
    # è·å–å®Œæ•´çš„è°ƒç”¨åºåˆ—
    sequence = ai_manager.get_call_sequence(task_enum)
    errors = []
    
    for item in sequence:
        endpoint = item["endpoint"]
        models = item["models"]
        temperature = item["temperature"]
        
        headers = {
            "Authorization": f"Bearer {endpoint.api_key}",
            "Content-Type": "application/json"
        }
        
        for model in models:
            try:
                payload = {
                    "model": model,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_content}
                    ],
                    "temperature": temperature
                }
                
                response = requests.post(
                    endpoint.base_url, 
                    headers=headers, 
                    json=payload, 
                    timeout=ai_manager.timeout
                )
                
                if response.status_code == 200:
                    result = response.json()
                    content = result['choices'][0]['message']['content']
                    # æ ‡è®°æˆåŠŸï¼Œæ¢å¤æ¥å£çŠ¶æ€
                    ai_manager.mark_endpoint_success(endpoint)
                    return content
                else:
                    error_msg = f"{endpoint.name}({model}): HTTP {response.status_code} {response.text[:50]}"
                    errors.append(error_msg)
                    # å¦‚æœé‡åˆ°ä¸¥é‡çš„è¿æ¥æˆ–æœåŠ¡é”™è¯¯ï¼Œè·³è¿‡è¯¥ç«¯ç‚¹çš„å‰©ä½™æ¨¡å‹ï¼Œé¿å…æ— æ•ˆé‡è¯•åˆ·å±
                    if response.status_code in [404, 401, 502, 503, 504]:
                        ai_manager.mark_endpoint_error(endpoint)
                        break 
                    if response.status_code in [429, 500]: # 429/500 å¯èƒ½åªæ˜¯æ¨¡å‹é—®é¢˜ï¼Œç»§ç»­å°è¯•å…¶ä»–æ¨¡å‹
                         ai_manager.mark_endpoint_error(endpoint)
                    
            except requests.Timeout:
                error_msg = f"{endpoint.name}({model}): è¯·æ±‚è¶…æ—¶"
                errors.append(error_msg)
                ai_manager.mark_endpoint_error(endpoint)
                continue
            except Exception as e:
                error_msg = f"{endpoint.name}({model}): {str(e)}"
                errors.append(error_msg)
                ai_manager.mark_endpoint_error(endpoint)
                continue
                
    last_error = errors[-1] if errors else "æ— å¯ç”¨ç«¯ç‚¹"
    return f"AI æœåŠ¡å½“å‰ä¸å¯ç”¨ (å°è¯•äº† {len(errors)} æ¬¡è°ƒç”¨ï¼Œæœ€åé”™è¯¯: {last_error})"


# ========== AI æ ¸å¿ƒé€»è¾‘ (éƒ¨åˆ†å·²è¿ç§») ==========


def _run_analysis_task(task_id, project_id):
    """åå°è¿è¡ŒAIåˆ†æä»»åŠ¡"""
    try:
        # åœ¨çº¿ç¨‹ä¸­éœ€è¦æ‰‹åŠ¨ç®¡ç†ä¸Šä¸‹æ–‡å¦‚æœç”¨åˆ° current_appï¼Œä½†è¿™é‡Œä¸»è¦æ˜¯DBæ“ä½œ
        # DatabasePoolæ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œget_db()ä¼šä¸ºæ–°çº¿ç¨‹åˆ›å»ºè¿æ¥
        
        conn = get_db()
        project = dict(conn.execute('SELECT * FROM projects WHERE id = ?', (project_id,)).fetchone())
        stages = [dict(s) for s in conn.execute('SELECT * FROM project_stages WHERE project_id = ?', (project_id,)).fetchall()]
        issues = [dict(i) for i in conn.execute('SELECT * FROM issues WHERE project_id = ? AND status != "å·²è§£å†³"', (project_id,)).fetchall()]
        interfaces = [dict(i) for i in conn.execute('SELECT * FROM interfaces WHERE project_id = ? AND status != "å·²å®Œæˆ"', (project_id,)).fetchall()]
        devices = [dict(d) for d in conn.execute('SELECT * FROM medical_devices WHERE project_id = ?', (project_id,)).fetchall()]
        members = [dict(m) for m in conn.execute('SELECT * FROM project_members WHERE project_id = ? AND status = "åœ¨å²—"', (project_id,)).fetchall()]
        departures = [dict(d) for d in conn.execute('SELECT * FROM project_departures WHERE project_id = ? ORDER BY created_at DESC LIMIT 3', (project_id,)).fetchall()]
        # Connection closed automatically by thread exit? No, need to close manually in thread or use context manager
        # Since we are not in request context, teardown won't run automatically? 
        # Actually executor threads are long lived? DatabasePool uses thread local.
        # We should close the connection at the end of the task.
        
        # æ‰«ææ½œåœ¨é£é™©ç‚¹
        detected_risks, risk_score = ai_service.analyze_project_risks(project_id)
        
        system_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„åŒ»ç–—ä¿¡æ¯åŒ–é¡¹ç›®æ€»ç›‘(PMO)ï¼Œæ“…é•¿ICU/æ‰‹éº»ç³»ç»Ÿå®æ–½ã€‚
        è¯·æ ¹æ®æä¾›çš„é¡¹ç›®æ•°æ®ï¼ˆåŒ…å«åŸºç¡€ä¿¡æ¯ã€è¿›åº¦ã€é—®é¢˜åŠå·¥ä½œæ—¥å¿—é£é™©æ‰«æç»“æœï¼‰ï¼Œè¿›è¡Œä¸¥å‰ä½†å»ºè®¾æ€§çš„è¯Šæ–­ã€‚
        è¾“å‡º Markdown æ ¼å¼ï¼Œä¸”å¿…é¡»åŒ…å«ä»¥ä¸‹å›ºå®šç»“æ„ï¼š
        
        1. **æ•´ä½“å¥åº·åº¦è¯„åˆ†** (0-100åˆ†) åŠç®€çŸ­è¯„è¯­ã€‚
        2. **é£é™©é›·è¾¾æ•°æ®**ï¼šè¯·åœ¨è¾“å‡ºçš„æœ€åï¼Œä½¿ç”¨å”¯ä¸€çš„JSONä»£ç å—è¿”å›ä»¥ä¸‹5ä¸ªç»´åº¦çš„è¯„åˆ†(0-10åˆ†ï¼Œåˆ†æ•°è¶Šé«˜è¡¨ç¤ºè¶Šç¨³å¥/é£é™©è¶Šä½)ï¼š
           - è¿›åº¦ (Progress): è®¡åˆ’ä¸å®é™…åŒ¹é…åº¦
           - æŠ€æœ¯ (Technical): æ¥å£ã€æ€§èƒ½ã€BugçŠ¶å†µ
           - äº¤ä»˜ (Delivery): ç¡¬ä»¶ã€ä¸Šçº¿ã€éªŒæ”¶è¿›åº¦
           - åè°ƒ (Coordination): ç”²æ–¹é…åˆã€å†…éƒ¨æ²Ÿé€š
           - é¢„ç®— (Budget): æˆæœ¬æ§åˆ¶ã€å·¥æ—¶æ¶ˆè€—
           ä»£ç å—æ ¼å¼å¿…é¡»ä¸º: ```json {"radar": {"è¿›åº¦": 8, "æŠ€æœ¯": 6, ...}} ```
        3. **æ ¸å¿ƒç—›ç‚¹è¯Šæ–­**ï¼šæ·±åº¦åˆ†æä¸ºä»€ä¹ˆä¼šå‡ºç°è¿™äº›é£é™©ç‚¹ã€‚
        4. **è¿½èµ¶å»ºè®®ä¸é¢„æ¡ˆ**ï¼šç»™å‡ºå…·ä½“çš„åº”å¯¹é¢„æ¡ˆã€‚
        5. **ä¸‹å‘¨é‡ç‚¹** (åŸºäºå½“å‰çŠ¶æ€æ¨èçš„ä¼˜å…ˆäº‹é¡¹)
        """.format(risk_score=risk_score)
        
        project_data_str = json.dumps({
            "project_info": project, 
            "stages_status": stages, 
            "pending_issues": issues,
            "pending_interfaces": interfaces, 
            "devices": devices, 
            "team_members": members,
            "departure_history": departures,
            "log_detected_risks": detected_risks,
            "calculated_risk_score": risk_score
        }, ensure_ascii=False)
        
        # Close DB reading connection before long API call
        close_db()
        
        analysis_result = call_deepseek_api(system_prompt, f"è¯·åˆ†æä»¥ä¸‹é¡¹ç›®æ•°æ®ï¼š\n{project_data_str}", task_type="analysis")
        
        # Re-open DB to save result
        data_hash = analytics_service.calculate_project_hash(project_id)
        analytics_service.save_report_cache(project_id, 'ai_analysis', analysis_result, data_hash)
        
        task_results[task_id] = {"status": "completed", "result": analysis_result}
        
    except Exception as e:
        task_results[task_id] = {"status": "failed", "error": str(e)}
        # Ensure db is closed in case of error
        close_db(e)

@app.route('/api/tasks/<task_id>', methods=['GET'])
def get_task_result(task_id):
    result = task_results.get(task_id)
    if result is None:
        return api_response(False, message="ä»»åŠ¡ä¸å­˜åœ¨ (Task not found)", code=404)
    return api_response(True, result)



# ========== å‘¨æŠ¥ç”Ÿæˆ API ==========
# --- Removed buggy partial definition of generate_weekly_report ---
    
def _run_weekly_report_task(task_id, project_id):
    """åå°è¿è¡Œå‘¨æŠ¥ç”Ÿæˆä»»åŠ¡"""
    try:
        conn = get_db()
        project = dict(conn.execute('SELECT * FROM projects WHERE id = ?', (project_id,)).fetchone())
        stages = [dict(s) for s in conn.execute('SELECT * FROM project_stages WHERE project_id = ? ORDER BY stage_order', (project_id,)).fetchall()]
        week_ago = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
        completed_tasks = conn.execute('''
            SELECT t.task_name, s.stage_name, t.completed_date 
            FROM tasks t JOIN project_stages s ON t.stage_id = s.id 
            WHERE s.project_id = ? AND t.is_completed = 1 AND t.completed_date >= ?
        ''', (project_id, week_ago)).fetchall()
        new_issues = conn.execute('SELECT * FROM issues WHERE project_id = ? AND created_at >= ?', (project_id, week_ago)).fetchall()
        pending_issues = conn.execute("SELECT * FROM issues WHERE project_id = ? AND status != 'å·²è§£å†³'", (project_id,)).fetchall()
        interfaces = conn.execute('SELECT * FROM interfaces WHERE project_id = ?', (project_id,)).fetchall()
        work_logs = conn.execute('SELECT * FROM work_logs WHERE project_id = ? AND log_date >= ? ORDER BY log_date', (project_id, week_ago)).fetchall()
        # Close reading connection
        close_db()
        
        system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŒ»ç–—ä¿¡æ¯åŒ–é¡¹ç›®ç»ç†ï¼Œè¯·ç”Ÿæˆä¸€ä»½æ­£å¼å‘¨æŠ¥ã€‚Markdownæ ¼å¼ï¼š
        # ğŸ“‹ [é¡¹ç›®åç§°] å‘¨æŠ¥
        **æŠ¥å‘Šå‘¨æœŸ**: YYYY-MM-DD ~ YYYY-MM-DD
        **é¡¹ç›®ç»ç†**: XXX | **å½“å‰è¿›åº¦**: XX%
        ## ä¸€ã€æœ¬å‘¨å·¥ä½œå®Œæˆæƒ…å†µ
        ## äºŒã€å½“å‰é¡¹ç›®é˜¶æ®µçŠ¶æ€ (è¡¨æ ¼)
        ## ä¸‰ã€é—®é¢˜ä¸é£é™©
        ## å››ã€ä¸‹å‘¨å·¥ä½œè®¡åˆ’
        ## äº”ã€éœ€è¦åè°ƒäº‹é¡¹
        """
        
        project_data = {
            "project": project, "stages": stages,
            "completed_tasks_this_week": [dict(t) for t in completed_tasks],
            "new_issues_this_week": [dict(i) for i in new_issues],
            "pending_issues": [dict(i) for i in pending_issues],
            "interfaces": [dict(i) for i in interfaces],
            "work_logs_this_week": [dict(w) for w in work_logs],
            "report_date": datetime.now().strftime('%Y-%m-%d')
        }
        
        # Update call with task_type='report'
        report = call_deepseek_api(system_prompt, f"è¯·ä¸ºä»¥ä¸‹é¡¹ç›®ç”Ÿæˆå‘¨æŠ¥ï¼š\n{json.dumps(project_data, ensure_ascii=False)}", task_type="report")
        
        data_hash = analytics_service.calculate_project_hash(project_id)
        analytics_service.save_report_cache(project_id, 'weekly_report', report, data_hash)
        
        task_results[task_id] = {"status": "completed", "result": report}
        
    except Exception as e:
        task_results[task_id] = {"status": "failed", "error": str(e)}
        close_db(e)

@app.route('/api/projects/<int:project_id>/weekly-report', methods=['POST'])
def generate_weekly_report(project_id):
    try:
        force_refresh = request.args.get('force', '0') == '1'
        if not force_refresh:
            cached = analytics_service.get_cached_report(project_id, 'weekly_report')
            if cached:
                # Note: cached is just the content string in get_cached_report version
                return api_response(True, {'report': cached, 'cached': True})
        
        # Generate Task ID
        task_id = str(uuid.uuid4())
        task_results[task_id] = {"status": "processing"}
        
        executor.submit(_run_weekly_report_task, task_id, project_id)
        
        return api_response(True, {"task_id": task_id, "status": "processing"})
    except Exception as e:
        app.logger.error(f"Generate Weekly Report Error: {e}")
        return api_response(False, message=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}", code=500)


    
def _run_all_report_task(task_id):
    """åå°è¿è¡Œå…¨å±€å‘¨æŠ¥ç”Ÿæˆä»»åŠ¡"""
    try:
        conn = get_db()
        projects = conn.execute("""
            SELECT * FROM projects WHERE status NOT IN ('å·²å®Œæˆ', 'å·²ç»ˆæ­¢')
            ORDER BY priority DESC, progress DESC
        """).fetchall()
        
        if not projects:
            close_db()
            task_results[task_id] = {"status": "failed", "error": "æ²¡æœ‰è¿›è¡Œä¸­çš„é¡¹ç›®"}
            return

        week_ago = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
        all_data = []
        for p in projects:
            pid = p['id']
            stages = [dict(s) for s in conn.execute('SELECT * FROM project_stages WHERE project_id = ? ORDER BY stage_order', (pid,)).fetchall()]
            issues = [dict(i) for i in conn.execute("SELECT * FROM issues WHERE project_id = ? AND status != 'å·²è§£å†³'", (pid,)).fetchall()]
            completed_tasks = [dict(t) for t in conn.execute('''
                SELECT t.task_name, s.stage_name, t.completed_date 
                FROM tasks t JOIN project_stages s ON t.stage_id = s.id 
                WHERE s.project_id = ? AND t.is_completed = 1 AND t.completed_date >= ?
            ''', (pid, week_ago)).fetchall()]
            new_issues = [dict(i) for i in conn.execute('SELECT * FROM issues WHERE project_id = ? AND created_at >= ?', (pid, week_ago)).fetchall()]
            interfaces = [dict(i) for i in conn.execute('SELECT * FROM interfaces WHERE project_id = ?', (pid,)).fetchall()]
            interface_completed = len([i for i in interfaces if i['status'] == 'å·²å®Œæˆ'])
            work_hours = conn.execute('SELECT SUM(work_hours) as total FROM work_logs WHERE project_id = ? AND log_date >= ?', (pid, week_ago)).fetchone()['total'] or 0
            
            all_data.append({
                "project": dict(p),
                "stages": stages,
                "pending_issues": issues,
                "pending_issues_count": len(issues),
                "critical_issues": [i for i in issues if i['severity'] == 'é«˜'],
                "completed_tasks_this_week": completed_tasks,
                "new_issues_this_week": new_issues,
                "interface_stats": f"{interface_completed}/{len(interfaces)}",
                "work_hours_this_week": work_hours
            })
        
        close_db()
        system_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é«˜çº§é¡¹ç›®æ€»ç›‘ï¼Œè´Ÿè´£ç›‘ç£å¤šä¸ªåŒ»ç–—ä¿¡æ¯åŒ–å®æ–½é¡¹ç›®ã€‚è¯·ç”Ÿæˆä¸€ä»½å…¨å±€é¡¹ç›®ç¾¤åˆ†æå‘¨æŠ¥ã€‚
        
        æŠ¥å‘Šå¿…é¡»åŒ…å«ä»¥ä¸‹ç»“æ„ï¼š
        1. ## ä¸€ã€é¡¹ç›®ç¾¤æ€»ä½“æ¦‚å†µ (å¿…é¡»åŒ…å«ä¸€ä¸ªMarkdownè¡¨æ ¼ï¼Œåˆ—å‡ºæ‰€æœ‰é¡¹ç›®çš„åç§°ã€åŒ»é™¢ã€è¿›åº¦ã€ç»ç†å’Œå½“å‰çŠ¶æ€)
        2. ## äºŒã€é‡ç‚¹å…³æ³¨é¡¹ç›®
        3. ## ä¸‰ã€å…±æ€§é—®é¢˜ä¸é£é™©
        4. ## å››ã€ä¸‹ä¸€æ­¥ç»Ÿç­¹è®¡åˆ’
        5. ## äº”ã€éœ€è¦èµ„æºæ”¯æŒ
        """
        report = call_deepseek_api(system_prompt, f"è¯·åŸºäºä»¥ä¸‹é¡¹ç›®æ•°æ®ç”Ÿæˆç®¡ç†å‘¨æŠ¥ï¼š\n{json.dumps(all_data, ensure_ascii=False)}", task_type="report")
        data_hash = analytics_service.calculate_all_projects_hash()
        analytics_service.save_report_cache(0, 'all_weekly_report', report, data_hash)
        task_results[task_id] = {"status": "completed", "result": report}
    except Exception as e:
        task_results[task_id] = {"status": "failed", "error": str(e)}
        close_db(e)

@app.route('/api/weekly-report/all', methods=['POST'])
def generate_all_projects_report():
    force_refresh = request.args.get('force', '0') == '1'
    if not force_refresh:
        cached = analytics_service.get_cached_report(0, 'all_weekly_report')
        if cached:
            return api_response(True, {'report': cached, 'cached': True})
    task_id = str(uuid.uuid4())
    task_results[task_id] = {"status": "processing"}
    executor.submit(_run_all_report_task, task_id)
    return api_response(True, {"task_id": task_id, "status": "processing"})

# ========== ç‡ƒå°½å›¾æ•°æ® API ==========
@app.route('/api/projects/<int:project_id>/burndown', methods=['GET'])
def get_burndown_data(project_id):
    conn = get_db()
    project = conn.execute('SELECT * FROM projects WHERE id = ?', (project_id,)).fetchone()
    if not project:
        close_db()
        return jsonify({'error': 'é¡¹ç›®ä¸å­˜åœ¨'}), 404
    
    # è·å–å†å²è®°å½•
    history = conn.execute('''
        SELECT record_date, progress, tasks_total, tasks_completed 
        FROM progress_history WHERE project_id = ? ORDER BY record_date
    ''', (project_id,)).fetchall()
    
    # è·å–å½“å‰çŠ¶æ€
    tasks_stats = conn.execute('''
        SELECT COUNT(*) as total, SUM(CASE WHEN is_completed = 1 THEN 1 ELSE 0 END) as completed
        FROM tasks t JOIN project_stages s ON t.stage_id = s.id WHERE s.project_id = ?
    ''', (project_id,)).fetchone()
    total_tasks = tasks_stats['total'] or 0
    completed_tasks = tasks_stats['completed'] or 0
    
    start_date_str = project['plan_start_date'] or project['created_at'][:10]
    end_date_str = project['plan_end_date'] or (datetime.now() + timedelta(days=30)).strftime('%Y-%m-%d')
    
    try:
        start_date = datetime.strptime(start_date_str, '%Y-%m-%d')
        end_date = datetime.strptime(end_date_str, '%Y-%m-%d')
    except:
        start_date = datetime.now() - timedelta(days=30)
        end_date = datetime.now() + timedelta(days=30)
    
    total_days = (end_date - start_date).days or 1
    today = datetime.now()
    
    ideal_line = []
    for i in range(total_days + 1):
        curr = start_date + timedelta(days=i)
        ideal_rem = total_tasks - (total_tasks * i / total_days)
        ideal_line.append({'date': curr.strftime('%Y-%m-%d'), 'value': round(max(0, ideal_rem), 1)})
    
    actual_line = []
    if history:
        for row in history:
            actual_line.append({'date': row['record_date'], 'value': row['tasks_total'] - row['tasks_completed']})
        
        # å¦‚æœæœ€åä¸€æ¡è®°å½•ä¸æ˜¯ä»Šå¤©ï¼Œæ·»åŠ ä»Šå¤©çš„å®æ—¶æ•°æ®
        if history[-1]['record_date'] != today.strftime('%Y-%m-%d'):
            actual_line.append({'date': today.strftime('%Y-%m-%d'), 'value': total_tasks - completed_tasks})
    else:
        # å…œåº•ï¼šå¦‚æœæ²¡æœ‰å†å²è®°å½•ï¼Œç”Ÿæˆç®€å•çš„ä¸¤ç‚¹çº¿ï¼ˆå¼€å§‹æ—¥å’Œä»Šæ—¥ï¼‰
        actual_line.append({'date': start_date.strftime('%Y-%m-%d'), 'value': total_tasks})
        if today > start_date:
            actual_line.append({'date': today.strftime('%Y-%m-%d'), 'value': total_tasks - completed_tasks})

    close_db()
    return jsonify({
        'project_name': project['project_name'],
        'total_tasks': total_tasks,
        'completed_tasks': completed_tasks,
        'ideal_line': ideal_line,
        'actual_line': actual_line
    })

# ========== ä»ªè¡¨ç›˜ç»Ÿè®¡ API ==========
@app.route('/api/dashboard/stats', methods=['GET'])
@cached(ttl=60)
def get_dashboard_stats():
    conn = get_db()
    total_projects = conn.execute("SELECT COUNT(*) as c FROM projects").fetchone()['c']
    in_progress = conn.execute("SELECT COUNT(*) as c FROM projects WHERE status = 'è¿›è¡Œä¸­'").fetchone()['c']
    completed = conn.execute("SELECT COUNT(*) as c FROM projects WHERE status = 'å·²å®Œæˆ'").fetchone()['c']
    delayed = conn.execute("SELECT COUNT(*) as c FROM projects WHERE plan_end_date < date('now') AND status NOT IN ('å·²å®Œæˆ', 'å·²ç»ˆæ­¢', 'å·²éªŒæ”¶', 'è´¨ä¿æœŸ')").fetchone()['c']
    on_departure = conn.execute("SELECT COUNT(*) as c FROM projects WHERE status IN ('æš‚åœ', 'ç¦»åœºå¾…è¿”')").fetchone()['c']
    total_issues = conn.execute("SELECT COUNT(*) as c FROM issues WHERE status != 'å·²è§£å†³'").fetchone()['c']
    critical_issues = conn.execute("SELECT COUNT(*) as c FROM issues WHERE status != 'å·²è§£å†³' AND severity = 'é«˜'").fetchone()['c']
    week_ago = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
    tasks_completed_this_week = conn.execute("SELECT COUNT(*) as c FROM tasks WHERE is_completed = 1 AND completed_date >= ?", (week_ago,)).fetchone()['c']
    
    # ç»Ÿè®¡é€¾æœŸé‡Œç¨‹ç¢‘æ€»æ•°
    overdue_milestones_total = conn.execute('''
        SELECT COUNT(*) as c FROM milestones 
        WHERE is_completed = 0 AND target_date < date('now')
    ''').fetchone()['c']

    
    # æŒ‰çŠ¶æ€åˆ†ç»„ç»Ÿè®¡
    status_stats = conn.execute('''
        SELECT status, COUNT(*) as count FROM projects GROUP BY status
    ''').fetchall()
    
    projects_progress = []
    rows = conn.execute('''
        SELECT p.id, p.project_name, p.hospital_name, p.progress, p.status, p.plan_end_date,
        (SELECT COUNT(*) FROM milestones m WHERE m.project_id = p.id AND m.is_completed = 0 AND m.target_date < date('now')) as overdue_count
        FROM projects p WHERE p.status NOT IN ('å·²å®Œæˆ', 'å·²ç»ˆæ­¢') 
        ORDER BY overdue_count DESC, progress DESC
    ''').fetchall()
    
    for row in rows:
        p_dict = dict(row)
        # è·å–è¯¥é¡¹ç›®çš„é£é™©å¾—åˆ†
        _, risk_score = scan_project_risks(p_dict['id'], conn.cursor())
        p_dict['risk_score'] = risk_score
        
        # åˆ¤å®šé˜¶æ®µ
        if p_dict['status'] in ['æš‚åœ', 'ç¦»åœºå¾…è¿”']: p_dict['phase'] = 'ç¦»åœº'
        elif p_dict['plan_end_date'] and p_dict['plan_end_date'] < datetime.now().strftime('%Y-%m-%d'): p_dict['phase'] = 'å»¶æœŸ'
        elif p_dict['progress'] < 30: p_dict['phase'] = 'å¯åŠ¨æœŸ'
        elif p_dict['progress'] < 70: p_dict['phase'] = 'å®æ–½ä¸­'
        else: p_dict['phase'] = 'æ”¶å°¾æœŸ'
        
        projects_progress.append(p_dict)

    
    upcoming_reminders = conn.execute('''
        SELECT n.*, p.project_name 
        FROM notifications n 
        LEFT JOIN projects p ON n.project_id = p.id
        WHERE n.is_read = 0 AND (n.due_date IS NULL OR n.due_date >= date('now'))
        ORDER BY n.due_date ASC LIMIT 10
    ''').fetchall()
    
    # æœ¬å‘¨å·¥æ—¶ç»Ÿè®¡
    week_hours = conn.execute('SELECT SUM(work_hours) as total FROM work_logs WHERE log_date >= ?', (week_ago,)).fetchone()['total'] or 0
    
    # Connection closed by teardown
    
    return api_response(True, {
        'stats': {
            'total_projects': total_projects, 'in_progress': in_progress,
            'completed': completed, 'delayed': delayed, 'on_departure': on_departure,
            'total_issues': total_issues, 'critical_issues': critical_issues,
            'tasks_completed_this_week': tasks_completed_this_week,
            'week_hours': round(week_hours, 1),
            'overdue_milestones': overdue_milestones_total
        },
        'status_stats': [dict(s) for s in status_stats],
        'projects_progress': [dict(p) for p in projects_progress],
        'upcoming_reminders': [dict(r) for r in upcoming_reminders]
    })


# ========== Analytics and Performance - Handled by analytics_bp



# ========== Notifications API - Migrated to monitor_routes ==========


# ========== é¡¹ç›®é‡Œç¨‹ç¢‘ç®¡ç† (å·²è¿ç§»è‡³ Blueprint) ==========


# ========== é¡¹ç›®åŸºç¡€ CRUD (å·²è¿ç§»è‡³ Blueprint) ==========


# ========== é¡¹ç›®åŸºç¡€ CRUD (å·²è¿ç§»è‡³ Blueprint) ==========

# ========== é˜¶æ®µ/ä»»åŠ¡ API (Migrated to task_routes) ==========

# ========== æ¥å£ç®¡ç† API ==========

# ========== æ¥å£ç®¡ç† API (å·²è¿ç§»è‡³ Blueprint) ==========

# ========== é—®é¢˜ç®¡ç† API ==========
@app.route('/api/projects/<int:project_id>/issues', methods=['POST'])
def add_issue(project_id):
    data = request.json
    conn = get_db()
    conn.execute('INSERT INTO issues (project_id, issue_type, description, severity, status) VALUES (?, ?, ?, ?, ?)',
                 (project_id, data['issue_type'], data['description'], data['severity'], data.get('status', 'å¾…å¤„ç†')))
    conn.commit()
    project = conn.execute('SELECT project_name FROM projects WHERE id = ?', (project_id,)).fetchone()
    close_db()
    
    if data['severity'] == 'é«˜':
        monitor_service.send_notification_async(
            f"ğŸš¨ æ–°å¢é«˜å±é—®é¢˜",
            f"é¡¹ç›®: {project['project_name']}\nç±»å‹: {data['issue_type']}\næè¿°: {data['description']}",
            'danger'
        )
    return jsonify({'success': True})

@app.route('/api/issues/<int:issue_id>', methods=['PUT'])
def update_issue(issue_id):
    data = request.json
    conn = get_db()
    resolved_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S') if data.get('status') == 'å·²è§£å†³' else None
    conn.execute('UPDATE issues SET issue_type=?, description=?, severity=?, status=?, resolved_at=? WHERE id=?',
                 (data.get('issue_type'), data.get('description'), data.get('severity'), data.get('status'), resolved_at, issue_id))
    conn.commit()
    close_db()
    return jsonify({'success': True})


# ========== Geolocation Analytics - Handled by analytics_bp

# ========== é—®é¢˜ç®¡ç† API (Migrated to task_routes) ==========

# ========== åŒ»ç–—è®¾å¤‡ç®¡ç† API (Migrated to task_routes/project_routes) ==========


# ========== Gantt Chart Data - Handled by analytics_bp

# ==================== V2.0 æ–°å¢ API ====================

# ========== è§’è‰²ç®¡ç† API (Placeholder) ==========

# ========== å·¥ä½œæ—¥å¿— API (Migrated to log_routes) ==========

# ========== æ–‡æ¡£ç®¡ç† API (Migrated to doc_routes) ==========

# ========== å˜æ›´ç®¡ç† API (Migrated to lifecycle_routes) ==========

# ========== éªŒæ”¶ç®¡ç† API (Migrated to lifecycle_routes) ==========

# ========== å®¢æˆ·æ»¡æ„åº¦ API (Migrated to lifecycle_routes) ==========

# ========== å›è®¿è®°å½• API (Migrated to lifecycle_routes) ==========

# ========== æ“ä½œæ—¥å¿— API ==========
@app.route('/api/operation-logs', methods=['GET'])
def get_operation_logs():
    conn = get_db()
    entity_type = request.args.get('entity_type')
    entity_id = request.args.get('entity_id')
    
    query = 'SELECT * FROM operation_logs WHERE 1=1'
    params = []
    
    if entity_type:
        query += ' AND entity_type = ?'
        params.append(entity_type)
    if entity_id:
        query += ' AND entity_id = ?'
        params.append(entity_id)
    
    query += ' ORDER BY created_at DESC LIMIT 100'
    logs = conn.execute(query, params).fetchall()
    close_db()
    return jsonify([dict(l) for l in logs])

# ========== æ•°æ®å¯¼å‡º API ==========
@app.route('/api/projects/<int:project_id>/export', methods=['GET'])
def export_project_data(project_id):
    """å¯¼å‡ºé¡¹ç›®å®Œæ•´æ•°æ®ä¸ºJSON"""
    conn = get_db()
    
    project = dict(conn.execute('SELECT * FROM projects WHERE id = ?', (project_id,)).fetchone())
    stages = [dict(s) for s in conn.execute('SELECT * FROM project_stages WHERE project_id = ?', (project_id,)).fetchall()]
    for stage in stages:
        stage['tasks'] = [dict(t) for t in conn.execute('SELECT * FROM tasks WHERE stage_id = ?', (stage['id'],)).fetchall()]
    
    data = {
        'export_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'project': project,
        'stages': stages,
        'interfaces': [dict(i) for i in conn.execute('SELECT * FROM interfaces WHERE project_id = ?', (project_id,)).fetchall()],
        'issues': [dict(i) for i in conn.execute('SELECT * FROM issues WHERE project_id = ?', (project_id,)).fetchall()],
        'milestones': [dict(m) for m in conn.execute('SELECT * FROM milestones WHERE project_id = ?', (project_id,)).fetchall()],
        'members': [dict(m) for m in conn.execute('SELECT * FROM project_members WHERE project_id = ?', (project_id,)).fetchall()],
        'contacts': [dict(c) for c in conn.execute('SELECT * FROM customer_contacts WHERE project_id = ?', (project_id,)).fetchall()],
         'departures': [dict(d) for d in conn.execute('SELECT * FROM project_departures WHERE project_id = ?', (project_id,)).fetchall()],
        'work_logs': [dict(w) for w in conn.execute('SELECT * FROM work_logs WHERE project_id = ?', (project_id,)).fetchall()],
        'documents': [dict(d) for d in conn.execute('SELECT * FROM project_documents WHERE project_id = ?', (project_id,)).fetchall()],
        'expenses': [dict(e) for e in conn.execute('SELECT * FROM project_expenses WHERE project_id = ?', (project_id,)).fetchall()],
        'changes': [dict(c) for c in conn.execute('SELECT * FROM project_changes WHERE project_id = ?', (project_id,)).fetchall()],
        'acceptances': [dict(a) for a in conn.execute('SELECT * FROM project_acceptances WHERE project_id = ?', (project_id,)).fetchall()],
        'satisfaction': [dict(s) for s in conn.execute('SELECT * FROM customer_satisfaction WHERE project_id = ?', (project_id,)).fetchall()],
        'follow_ups': [dict(f) for f in conn.execute('SELECT * FROM follow_up_records WHERE project_id = ?', (project_id,)).fetchall()],
        'devices': [dict(d) for d in conn.execute('SELECT * FROM medical_devices WHERE project_id = ?', (project_id,)).fetchall()]
    }
    
    close_db()
    return jsonify(data)


# ========== Global Analytics - Handled by analytics_bp

# ========== å®¡æ‰¹ä¸­å¿ƒ API ==========
@app.route('/api/approvals/pending', methods=['GET'])
def get_pending_approvals():
    """è·å–æ‰€æœ‰å¾…å®¡æ‰¹é¡¹"""
    conn = get_db()
    
    # å¾…å®¡æ‰¹å˜æ›´
    changes = conn.execute('''
        SELECT c.*, p.project_name, p.hospital_name 
        FROM project_changes c
        JOIN projects p ON c.project_id = p.id
        WHERE c.status = 'å¾…å®¡æ‰¹'
    ''').fetchall()
    
    # å¾…å®¡æ‰¹ç¦»åœº (ç¦»åœºæœ¬èº«ç›®å‰æ²¡æœ‰ç‹¬ç«‹çŠ¶æ€ï¼Œä½†å¯ä»¥æ ¹æ®ç¦»åœºè®°å½•ä¸­çš„å¤‡æ³¨æˆ–ç‰¹å®šå­—æ®µåˆ¤æ–­ï¼Œæˆ–è€…ç›´æ¥æ ¹æ®æœªè¿”åœºä¸”éœ€è¦å®¡æ ¸çš„è§„åˆ™)
    # è¿™é‡Œç®€å•èµ·è§ï¼Œç›®å‰ç¦»åœºç”³è¯·åœ¨add_project_departureä¸­æ˜¯ç›´æ¥ç”Ÿæ•ˆçš„ï¼Œ
    # æˆ‘ä»¬å¯ä»¥å¢åŠ ä¸€ä¸ª status å­—æ®µç»™ project_departuresï¼Œæˆ–è€…ç›´æ¥è®©ç”¨æˆ·å®¡æ ¸â€œå˜æ›´ç”³è¯·â€ä¸­çš„äººå‘˜/æ—¶é—´å˜æ›´
    
    close_db()
    return jsonify({
        'changes': [dict(c) for c in changes],
        'departures': [] # é¢„ç•™
    })

# ========== çŸ¥è¯†åº“ (KB) API ==========
@app.route('/api/kb', methods=['GET'])
def get_kb_list():
    category = request.args.get('category')
    search = request.args.get('search')
    conn = get_db()
    query = 'SELECT * FROM knowledge_base WHERE 1=1'
    params = []
    if category:
        query += ' AND category = ?'
        params.append(category)
    if search:
        query += ' AND (title LIKE ? OR content LIKE ? OR tags LIKE ?)'
        params.extend([f'%{search}%', f'%{search}%', f'%{search}%'])
    query += ' ORDER BY created_at DESC'
    items = conn.execute(query, params).fetchall()
    close_db()
    return jsonify([dict(i) for i in items])

@app.route('/api/kb/<int:kid>', methods=['GET'])
def get_kb_item(kid):
    conn = get_db()
    item = conn.execute('SELECT * FROM knowledge_base WHERE id = ?', (kid,)).fetchone()
    close_db()
    if item:
        return jsonify(dict(item))
    return jsonify({'error': 'Item not found'}), 404

@app.route('/api/kb', methods=['POST'])
def add_kb_item():
    try:
        conn = get_db()
        
        # æ”¯æŒ multipart/form-data æˆ– JSON
        if request.content_type and 'multipart/form-data' in request.content_type:
            data = request.form.to_dict()
            file = request.files.get('attachment')
        else:
            data = request.json
            file = None

        attachment_path = None
        if file and file.filename != '':
            try:
                # ä½¿ç”¨ç™¾åº¦ç½‘ç›˜ä¸Šä¼ 
                # é¡¹ç›®IDä½œä¸ºç›®å½•éš”ç¦»
                # åªæœ‰å½“ file å¯¹è±¡éç©ºä¸”æœ‰å†…å®¹æ—¶æ‰ä¸Šä¼ 
                project_id = data.get('project_id') or 'common'
                attachment_path = storage_service.upload_file(file, project_id)
            except Exception as e:
                # æ‰“å°å®Œæ•´å †æ ˆä»¥æ–¹ä¾¿è°ƒè¯•
                import traceback
                traceback.print_exc()
                return jsonify({'success': False, 'message': f'ä¸Šä¼ å¤±è´¥: {str(e)}'}), 500

        conn.execute('''
            INSERT INTO knowledge_base (category, title, content, tags, assoc_stage, project_id, author, attachment_path, external_link)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (data.get('category'), data.get('title'), data.get('content'), data.get('tags'), 
              data.get('assoc_stage'), data.get('project_id'), data.get('author'),
              attachment_path, data.get('external_link')))
        conn.commit()
        close_db()
        return jsonify({'success': True})
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'message': f'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}'}), 500

@app.route('/api/kb/<int:kid>', methods=['PUT'])
def update_kb_item(kid):
    try:
        conn = get_db()
        
        # æ”¯æŒ multipart/form-data æˆ– JSON
        if request.content_type and 'multipart/form-data' in request.content_type:
            data = request.form.to_dict()
            file = request.files.get('attachment')
        else:
            data = request.json
            file = None
            
        # è·å–æ—§æ•°æ®
        old_item = conn.execute('SELECT attachment_path FROM knowledge_base WHERE id = ?', (kid,)).fetchone()
        attachment_path = old_item['attachment_path'] if old_item else None

        if file and file.filename != '':
            try:
                # 1. ä¸Šä¼ æ–°æ–‡ä»¶
                project_id = data.get('project_id') or 'common'
                new_path = storage_service.upload_file(file, project_id)
                
                # 2. å¦‚æœæˆåŠŸï¼Œå°è¯•åˆ é™¤æ—§æ–‡ä»¶ (å¦‚æœå­˜åœ¨ä¸”ä¸æ˜¯åŒä¸€ä¸ªæ–‡ä»¶)
                if attachment_path and attachment_path != new_path:
                    try:
                        if not os.path.exists(attachment_path): # åªæœ‰å½“å®ƒä¸æ˜¯æœ¬åœ°æ–‡ä»¶æ—¶æ‰è°ƒç”¨ç½‘ç›˜åˆ é™¤
                             storage_service.delete_file(attachment_path)
                    except:
                        pass # åˆ é™¤æ—§æ–‡ä»¶å¤±è´¥ä¸å½±å“æ›´æ–°
                
                attachment_path = new_path
            except Exception as e:
                import traceback
                traceback.print_exc()
                return jsonify({'success': False, 'message': f'ä¸Šä¼ æ–‡ä»¶æ›´æ–°å¤±è´¥: {str(e)}'}), 500

        conn.execute('''
            UPDATE knowledge_base SET category=?, title=?, content=?, tags=?, assoc_stage=?, 
            attachment_path=?, external_link=?, updated_at=CURRENT_TIMESTAMP
            WHERE id=?
        ''', (data.get('category'), data.get('title'), data.get('content'), data.get('tags'), 
              data.get('assoc_stage'), attachment_path, data.get('external_link'), kid))
        conn.commit()
        close_db()
        return jsonify({'success': True})
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'message': f'æ›´æ–°å¤±è´¥: {str(e)}'}), 500

@app.route('/api/kb/<int:kid>/download', methods=['GET'])
def download_kb_attachment(kid):
    conn = get_db()
    item = conn.execute('SELECT title, attachment_path FROM knowledge_base WHERE id = ?', (kid,)).fetchone()
    close_db()
    
    if item and item['attachment_path']:
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ¬åœ°è·¯å¾„ (æ—§æ•°æ®)
            if os.path.exists(item['attachment_path']):
                 return send_file(item['attachment_path'], as_attachment=True, download_name=os.path.basename(item['attachment_path']))
            
            # å°è¯•ä»ç½‘ç›˜ä¸‹è½½
            local_path = storage_service.download_file(item['attachment_path'])
            
            # å‘é€æ–‡ä»¶ååˆ é™¤ä¸´æ—¶æ–‡ä»¶? send_file ä¸ä¼šè‡ªåŠ¨åˆ é™¤
            # å¯ä»¥ä½¿ç”¨ after_request æˆ–è€…ä¸“é—¨çš„ cleanup
            # è¿™é‡Œç®€å•èµ·è§ï¼Œä¸ç«‹å³åˆ é™¤ï¼Œä¾é ç³»ç»Ÿå®šæœŸæ¸…ç† temp_downloads æˆ–ä¸‹æ¬¡é‡å¯æ¸…ç†
            
            # ä½¿ç”¨ KB æ ‡é¢˜ + åŸå§‹æ‰©å±•å ä½œä¸ºä¸‹è½½æ–‡ä»¶å
            params_name = os.path.basename(item['attachment_path']) # fallback
            try:
                ext = os.path.splitext(item['attachment_path'])[1]
                if not ext:
                    ext = ""
                # ç®€å•æ¸…ç† title ä¸­çš„éæ³•å­—ç¬¦
                safe_title = "".join([c for c in item['title'] if c.isalnum() or c in (' ', '-', '_', '.', '(', ')', 'ã€', 'ã€‘', 'ï¼ˆ', 'ï¼‰')]).strip()
                if not safe_title:
                   safe_title = "download"
                filename = f"{safe_title}{ext}"
            except:
                filename = params_name
            
            # encode for header? flask send_file handles unicode usually, but safe_title helps
            return send_file(local_path, as_attachment=True, download_name=filename)
        except Exception as e:
            return jsonify({'error': f'ä¸‹è½½å¤±è´¥: {str(e)}'}), 500
            
    return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404

@app.route('/api/kb/<int:kid>', methods=['DELETE'])
def delete_kb_item(kid):
    conn = get_db()
    # å…ˆè·å–é™„ä»¶è·¯å¾„
    item = conn.execute('SELECT attachment_path FROM knowledge_base WHERE id = ?', (kid,)).fetchone()
    if item and item['attachment_path']:
        # å°è¯•åˆ é™¤ç½‘ç›˜æ–‡ä»¶
        if not os.path.exists(item['attachment_path']): # ç®€å•åˆ¤æ–­éæœ¬åœ°æ–‡ä»¶
             storage_service.delete_file(item['attachment_path'])
             
    conn.execute('DELETE FROM knowledge_base WHERE id = ?', (kid,))
    conn.commit()
    close_db()
    return jsonify({'success': True})

# ========== ç¡¬ä»¶èµ„äº§ç®¡ç† API ==========
@app.route('/api/assets', methods=['GET'])
def get_assets():
    status = request.args.get('status')
    conn = get_db()
    query = 'SELECT a.*, p.project_name FROM hardware_assets a LEFT JOIN projects p ON a.current_project_id = p.id'
    if status:
        query += ' WHERE a.status = ?'
        items = conn.execute(query, (status,)).fetchall()
    else:
        items = conn.execute(query).fetchall()
    close_db()
    return jsonify([dict(i) for i in items])

@app.route('/api/assets', methods=['POST'])
def add_asset():
    data = request.json
    conn = get_db()
    conn.execute('''
        INSERT INTO hardware_assets (asset_name, sn, model, status, current_project_id, location, operator)
        VALUES (?, ?, ?, ?, ?, ?, ?)
    ''', (data['asset_name'], data.get('sn'), data.get('model'), data.get('status', 'åœ¨åº“'),
          data.get('current_project_id'), data.get('location'), data.get('operator')))
    conn.commit()
    close_db()
    return jsonify({'success': True})

@app.route('/api/assets/<int:aid>/status', methods=['PUT'])
def update_asset_status(aid):
    data = request.json
    conn = get_db()
    conn.execute('''
        UPDATE hardware_assets SET status=?, current_project_id=?, location=?, operator=?, updated_at=CURRENT_TIMESTAMP
        WHERE id=?
    ''', (data['status'], data.get('current_project_id'), data.get('location'), data.get('operator'), aid))
    conn.commit()
    close_db()
    return jsonify({'success': True})

@app.route('/api/assets/<int:aid>', methods=['DELETE'])
def delete_asset(aid):
    conn = get_db()
    conn.execute('DELETE FROM hardware_assets WHERE id = ?', (aid,))
    conn.commit()
    close_db()
    return jsonify({'success': True})

# ========== Workload Analytics - Handled by analytics_bp



# ========== Global Briefing - Handled by analytics_bp

@app.route('/api/ai/risk-analysis', methods=['POST'])
def ai_risk_analysis():
    """
    é¡¹ç›®é£é™©é¢„è­¦åˆ†æ
    """
    data = request.json
    project_id = data.get('project_id')
    if not project_id:
        return jsonify({'error': 'é¡¹ç›®IDä¸èƒ½ä¸ºç©º'}), 400

    conn = get_db()
    cursor = conn.cursor()
    
    # 1. é‡‡é›†é¡¹ç›®æ·±åº¦æ•°æ®
    # åŸºæœ¬ä¿¡æ¯
    row = conn.execute("SELECT * FROM projects WHERE id = ?", (project_id,)).fetchone()
    if not row:
        return jsonify({'error': 'é¡¹ç›®ä¸å­˜åœ¨'}), 404
        
    project = dict(row)
    
    # æœ€è¿‘ 5 æ¡æ—¥å¿—
    cursor.execute("SELECT work_content, issues_encountered FROM work_logs WHERE project_id = ? ORDER BY log_date DESC LIMIT 5", (project_id,))
    logs = [f"å†…å®¹: {r[0]}, é—®é¢˜: {r[1]}" for r in cursor.fetchall()]
    
    # æœªè§£å†³çš„é—®é¢˜
    # schema correction: issues table has description, severity, status (no title, priority)
    cursor.execute("SELECT description, severity, status FROM issues WHERE project_id = ? AND status != 'å·²è§£å†³'", (project_id,))
    issues = [f"[{r[1]}] {r[0]} ({r[2]})" for r in cursor.fetchall()]

    # 2. æ„å»º Prompt
    prompt = f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„åŒ»ç–—ä¿¡æ¯åŒ–äº¤ä»˜ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹é¡¹ç›®çš„ã€äº¤ä»˜é£é™©ã€‘ã€‚

ã€é¡¹ç›®ä¿¡æ¯ã€‘:
åç§°: {project['project_name']}
å½“å‰çŠ¶æ€: {project['status']}
è¿›åº¦: {project['progress']}%
åºŠä½æ•°/æ‰‹æœ¯å®¤: {project.get('icu_beds',0)}/{project.get('operating_rooms',0)}

ã€è¿‘æœŸæ—¥å¿—æ‘˜è¦ã€‘:
{chr(10).join(logs) if logs else "æ— è¿‘æœŸæ—¥å¿—"}

ã€å­˜ç–‘é—®é¢˜ã€‘:
{chr(10).join(issues) if issues else "æ— æœªè§£å†³é—®é¢˜"}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯è®¡ç®—ä¸€ä¸ªã€é£é™©åˆ†æ•°ã€‘ (0-100ï¼Œ0ä¸ºå®‰å…¨ï¼Œ100ä¸ºæé«˜å±)ï¼Œå¹¶ç»™å‡º 1-2 å¥ç®€æ´çš„åˆ†æå»ºè®®ã€‚
å¿…é¡»ä¸¥æ ¼æŒ‰ä»¥ä¸‹ JSON æ ¼å¼å›å¤:
{{"risk_score": 45, "analysis": "ä¸»è¦é£é™©åœ¨äºæ¥å£è”è°ƒæ»å..."}}
"""

    from ai_utils import call_ai
    from ai_config import TaskType
    res_text = call_ai(prompt, TaskType.ANALYSIS)
    
    # è§£æ JSON
    try:
        # å°è¯•æå– JSON éƒ¨åˆ†
        import json
        json_match = re.search(r'\{.*\}', res_text, re.DOTALL)
        if json_match:
            res_data = json.loads(json_match.group())
        else:
            res_data = {"risk_score": 0, "analysis": "åˆ†æå¤±è´¥"}
    except:
        res_data = {"risk_score": 0, "analysis": "è§£æå¼‚å¸¸"}
        
    return jsonify(res_data)

@app.route('/api/ai/ask-kb', methods=['POST'])
def ai_ask_kb():
    """
    çŸ¥è¯†åº“ AI é—®ç­” (RAG)
    """
    data = request.json
    question = data.get('question', '')
    if not question:
        return jsonify({'error': 'é—®é¢˜ä¸èƒ½ä¸ºç©º'}), 400

    try:
        conn = get_db()
        cursor = conn.cursor()
        
        try:
            cursor.execute("SELECT id, title, content, category, tags FROM knowledge_base")
            columns = [column[0] for column in cursor.description]
            kb_items = [dict(zip(columns, row)) for row in cursor.fetchall()]
        except sqlite3.OperationalError:
            # è¡¨ä¸å­˜åœ¨æ—¶çš„é™çº§å¤„ç†
            kb_items = []
        
        # 2. æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
        from rag_service import rag_service
        context = rag_service.retrieve_context(question, kb_items, top_k=3)
        
        if not context:
            prompt = f"ç”¨æˆ·é—®äº†å…³äºçŸ¥è¯†åº“çš„é—®é¢˜: '{question}'ã€‚ç›®å‰çŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›´æ¥åŒ¹é…çš„æ¡ç›®ã€‚è¯·åŸºäºä½ çš„ä¸“ä¸šçŸ¥è¯†ç»™å‡ºè§£ç­”ã€‚"
        else:
            prompt = f"""
    ä½ æ˜¯ä¸€ä½é‡ç—‡æ‰‹éº»åŒ»ç–—ä¿¡æ¯åŒ–äº¤ä»˜ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹ã€çŸ¥è¯†åº“å‚è€ƒã€‘å›ç­”ç”¨æˆ·çš„ã€é—®é¢˜ã€‘ã€‚
    
    ã€çŸ¥è¯†åº“å‚è€ƒã€‘:
    {context}
    
    ã€é—®é¢˜ã€‘:
    {question}
    
    è¯·ç”¨ä¸“ä¸šç®€æ´çš„è¯­è¨€å›ç­”ã€‚
    """

        # 3. è°ƒç”¨ AI
        from ai_utils import call_ai
        from ai_config import TaskType
        answer = call_ai(prompt, TaskType.SUMMARY)
        
        return jsonify({
            'answer': answer,
            'has_context': bool(context)
        })
    except Exception as e:
        print(f"AI/KB Error: {e}")
        return jsonify({'error': str(e), 'answer': 'æŠ±æ­‰ï¼ŒAI æš‚æ—¶æ— æ³•å›ç­”ï¼ˆç³»ç»Ÿé”™è¯¯ï¼‰ã€‚'}), 500

@app.route('/api/ai/summarize-weekly', methods=['POST'])
def ai_summarize_weekly():
    try:
        data = request.json
        project_id = data.get('project_id')
        conn = get_db()
        project = conn.execute('SELECT * FROM projects WHERE id = ?', (project_id,)).fetchone()
        
        if not project:
            return jsonify({'summary': 'Project not found'}), 404

        # è·å–æ­¤é¡¹ç›®çš„è¿‘æœŸåŠ¨æ€ (æ—¥å¿—ã€é—®é¢˜ã€é‡Œç¨‹ç¢‘)
        logs = conn.execute('SELECT * FROM work_logs WHERE project_id = ? ORDER BY log_date DESC LIMIT 10', (project_id,)).fetchall()
        issues = conn.execute('SELECT * FROM issues WHERE project_id = ? AND status != "å·²è§£å†³" LIMIT 10', (project_id,)).fetchall()
        
        context = f"""
        ã€é¡¹ç›®ä¿¡æ¯ã€‘
        åç§°: {project['project_name']}
        è¿›åº¦: {project['progress']}%
        çŠ¶æ€: {project['status']}
        
        ã€è¿‘æœŸæ—¥å¿—ã€‘
        {chr(10).join([f"- {l['log_date']} {l['member_name']}: {l['work_content']}" for l in logs])}
        
        ã€å¾…è§£å†³é—®é¢˜ã€‘
        {chr(10).join([f"- {i['issue_type']} ({i['severity']}): {i['description']}" for i in issues])}
        """
        
        prompt = f"""
        è¯·ä¸ºé¡¹ç›®ç”Ÿæˆå‘¨æŠ¥æ€»ç»“ (Markdownæ ¼å¼)ã€‚
        é‡ç‚¹å…³æ³¨ï¼šæœ¬å‘¨ä¸»è¦è¿›å±•ã€å½“å‰é£é™©ä¸ä¸‹å‘¨è®¡åˆ’ã€‚
        
        {context}
        """
        
        from ai_utils import call_ai
        # ä½¿ç”¨ 'summary' ä»»åŠ¡ç±»å‹
        summary = call_ai(prompt, task_type='summary')
        
        return jsonify({'summary': summary})
    except Exception as e:
        print(f"Weekly Report Error: {e}")
        return jsonify({'summary': f"ç”Ÿæˆå‘¨æŠ¥å¤±è´¥: {str(e)}"}), 500
    finally:
        close_db()

@app.route('/api/projects/<int:project_id>/share/toggle', methods=['POST'])
def toggle_project_share(project_id):
    """
    å¯ç”¨/ç¦ç”¨é¡¹ç›®åˆ†äº«
    """
    data = request.json
    enabled = 1 if data.get('enabled') else 0
    
    conn = get_db()
    cursor = conn.cursor()
    
    if enabled:
        # å¦‚æœå¯ç”¨ï¼Œç¡®ä¿æœ‰ token
        import uuid
        share_token = str(uuid.uuid4()).replace('-', '')[:16]
        cursor.execute("UPDATE projects SET share_enabled = 1, share_token = ? WHERE id = ?", (share_token, project_id))
    else:
        cursor.execute("UPDATE projects SET share_enabled = 0 WHERE id = ?", (project_id,))
        share_token = None
        
    conn.commit()
    close_db()
    return jsonify({'success': True, 'share_token': share_token})

@app.route('/share/<string:token>')
def public_share_page(token):
    """
    å…¬å…±é¢„è§ˆé¡µé¢ (æ— éœ€ç™»å½•)
    """
    conn = get_db()
    cursor = conn.cursor()
    
    # 1. æŸ¥æ‰¾å¼€å¯äº†åˆ†äº«çš„å¯¹åº”é¡¹ç›®
    cursor.execute("SELECT * FROM projects WHERE share_token = ? AND share_enabled = 1", (token,))
    row = cursor.fetchone()
    if not row:
        return "è¯¥åˆ†äº«é“¾æ¥ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ", 404
        
    columns = [column[0] for column in cursor.description]
    project = dict(zip(columns, row))
    project_id = project['id']
    
    # 2. åŠ è½½é‡Œç¨‹ç¢‘
    cursor.execute("SELECT * FROM milestones WHERE project_id = ? ORDER BY target_date ASC", (project_id,))
    project['milestones'] = [dict(zip([c[0] for c in cursor.description], r)) for r in cursor.fetchall()]
    
    # 3. åŠ è½½è¿›åº¦é˜¶æ®µï¼ˆåŠ¨æ€è®¡ç®—è¿›åº¦ï¼Œä¸ä¸»ç³»ç»Ÿä¸€è‡´ï¼‰
    cursor.execute("SELECT * FROM project_stages WHERE project_id = ? ORDER BY stage_order ASC", (project_id,))
    stages_raw = [dict(zip([c[0] for c in cursor.description], r)) for r in cursor.fetchall()]
    
    # æ€§èƒ½ä¼˜åŒ–ï¼šä¸€æ¬¡æ€§è·å–æ‰€æœ‰é˜¶æ®µçš„ä»»åŠ¡ï¼Œé¿å…N+1æŸ¥è¯¢
    stage_ids = [s['id'] for s in stages_raw]
    if stage_ids:
        placeholders = ','.join('?' * len(stage_ids))
        cursor.execute(f"SELECT * FROM tasks WHERE stage_id IN ({placeholders})", stage_ids)
        all_tasks = cursor.fetchall()
        # æŒ‰stage_idåˆ†ç»„
        tasks_by_stage = {}
        for t in all_tasks:
            sid = t[1]  # stage_idæ˜¯ç¬¬2åˆ—
            if sid not in tasks_by_stage:
                tasks_by_stage[sid] = []
            tasks_by_stage[sid].append(t)
    else:
        tasks_by_stage = {}
    
    stages_list = []
    for stage in stages_raw:
        tasks = tasks_by_stage.get(stage['id'], [])
        if tasks:
            completed = sum(1 for t in tasks if t[3])  # is_completedæ˜¯ç¬¬4åˆ—(0-indexed: id, stage_id, task_name, is_completed)
            stage['progress'] = int(completed / len(tasks) * 100)
        stages_list.append(stage)
    
    project['stages'] = stages_list

    close_db()
    return render_template('share_project.html', project=project)

@app.route('/api/ai/health', methods=['GET'])
def get_ai_health():
    from ai_config import ai_manager
    nodes = []
    for ep in ai_manager.endpoints:
        nodes.append({
            "name": ep.name,
            "status": "OK" if ep.is_available else "OFFLINE",
            "priority": ep.priority,
            "error_count": ep.error_count,
            "last_error_time": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(ep.last_error_time)) if ep.last_error_time > 0 else "ä»æœªå‡ºé”™"
        })
    return jsonify({"nodes": nodes})

@app.route('/api/ai/health/trigger', methods=['POST'])
def trigger_ai_health_check():
    from ai_config import ai_manager
    ai_manager.check_all_endpoints_health()
    return jsonify({"success": True, "message": "å·²æ‰‹åŠ¨è§¦å‘å…¨å±€ AI èŠ‚ç‚¹æ£€æµ‹"})

@app.route('/api/projects/<int:project_id>/ai-analyze', methods=['POST'])
def ai_analyze_project(project_id):
    try:
        conn = get_db()
        project = conn.execute('SELECT * FROM projects WHERE id = ?', (project_id,)).fetchone()
        
        if not project:
            return jsonify({'error': 'é¡¹ç›®ä¸å­˜åœ¨'}), 404

        # è·å–æ›´å¤šé¡¹ç›®ä¸Šä¸‹æ–‡
        issues = conn.execute('SELECT * FROM issues WHERE project_id = ?', (project_id,)).fetchall()
        tasks = conn.execute('''
            SELECT t.* FROM tasks t
            JOIN project_stages s ON t.stage_id = s.id
            WHERE s.project_id = ?
        ''', (project_id,)).fetchall()
        
        # å®‰å…¨å¤„ç†å¯èƒ½ä¸å­˜åœ¨çš„å­—æ®µ
        risk_score = project['risk_score'] if 'risk_score' in project.keys() else 0
        
        context = f"""
        é¡¹ç›®: {project['project_name']}
        å½“å‰é˜¶æ®µ: {project['status']}
        è¿›åº¦: {project['progress']}%
        é€¾æœŸé£é™©: {risk_score}
        
        è¿›è¡Œä¸­é—®é¢˜æ•°: {len([i for i in issues if i['status'] != 'å·²è§£å†³'])}
        ä¸¥é‡é—®é¢˜æ•°: {len([i for i in issues if i['severity'] == 'é«˜' and i['status'] != 'å·²è§£å†³'])}
        æœªå®Œæˆä»»åŠ¡æ•°: {len([t for t in tasks if not t['is_completed']])}
        """
        
        prompt = f"""
        è¯·ä½œä¸ºä¸€ä½èµ„æ·±PMOä¸“å®¶ï¼Œå¯¹è¯¥é¡¹ç›®è¿›è¡Œæ·±åº¦è¯Šæ–­ã€‚
        
        ã€è¾“å‡ºè¦æ±‚ã€‘
        1. ç”Ÿæˆä¸€ä»½Markdownæ ¼å¼çš„è¯Šæ–­æŠ¥å‘Šã€‚
        2. åŒ…å«ï¼šã€è¿›åº¦åˆ†æã€‘ã€ã€é£é™©é¢„è­¦ã€‘ã€ã€ä¼˜åŒ–å»ºè®®ã€‘ã€‚
        3. è¯­æ°”è¦ä¸“ä¸šã€çŠ€åˆ©ã€ç›´å‡»ç—›ç‚¹ã€‚
        4. **é‡è¦**ï¼šåœ¨æŠ¥å‘Šæœ€åï¼Œå¿…é¡»è¾“å‡ºä¸€æ®µJSONæ ¼å¼çš„é›·è¾¾å›¾æ•°æ®ï¼ŒåŒ…å«5ä¸ªç»´åº¦ï¼ˆè¿›åº¦ã€è´¨é‡ã€é£é™©ã€èµ„æºã€æ²Ÿé€šï¼‰ï¼Œæ¯ä¸ªç»´åº¦1-10åˆ†ã€‚
        5. JSONæ ¼å¼å¦‚ä¸‹ï¼Œå¿…é¡»åŒ…å«åœ¨ ```json ``` ä»£ç å—ä¸­ï¼š
        ```json
        {{
            "radar": {{
                "è¿›åº¦": 8,
                "è´¨é‡": 7,
                "é£é™©": 6,
                "èµ„æº": 9,
                "æ²Ÿé€š": 8
            }}
        }}
        ```
        
        ã€é¡¹ç›®æ•°æ®ã€‘
        {context}
        """
        
        from ai_utils import call_ai
        analysis = call_ai(prompt, task_type='analysis')
        
        close_db()
        return jsonify({'analysis': analysis})
        
    except Exception as e:
        app.logger.error(f"AI Analysis Error: {e}")
        return jsonify({'error': str(e), 'analysis': 'AI åˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æŸ¥çœ‹æœåŠ¡å™¨æ—¥å¿—ã€‚'}), 500

@app.route('/api/ai/generate-daily-report', methods=['POST'])
def ai_generate_daily_report():
    data = request.json
    project_id = data.get('project_id')
    report_date = data.get('date', datetime.now().strftime('%Y-%m-%d'))
    
    conn = get_db()
    project = conn.execute('SELECT * FROM projects WHERE id = ?', (project_id,)).fetchone()
    
    # 1. ä»Šæ—¥æ—¥å¿—
    daily_logs = conn.execute('''
        SELECT * FROM work_logs 
        WHERE project_id = ? AND log_date = ?
    ''', (project_id, report_date)).fetchall()
    
    # 2. ä»Šæ—¥å®Œæˆä»»åŠ¡
    completed_tasks = conn.execute('''
        SELECT t.* FROM tasks t
        JOIN project_stages s ON t.stage_id = s.id
        WHERE s.project_id = ? AND t.is_completed = 1 AND t.completed_date = ?
    ''', (project_id, report_date)).fetchall()
    
    # 3. æ´»è·ƒé—®é¢˜ (é«˜é£é™©æˆ–å¾…å¤„ç†)
    active_issues = conn.execute('''
        SELECT * FROM issues 
        WHERE project_id = ? AND status != 'å·²è§£å†³'
        ORDER BY severity DESC LIMIT 5
    ''', (project_id,)).fetchall()
    
    # 4. æ˜æ—¥è®¡åˆ’ (ä»ä»Šæ—¥æ—¥å¿—æå–)
    tmr_plans = [l['tomorrow_plan'] for l in daily_logs if l['tomorrow_plan']]

    # æ„å»ºä¸Šä¸‹æ–‡
    context = f"""
    ã€é¡¹ç›®åŸºç¡€ä¿¡æ¯ã€‘
    é¡¹ç›®åç§°: {project['project_name']}
    å½“å‰é˜¶æ®µ: {project['status']}
    æ•´ä½“è¿›åº¦: {project['progress']}%
    æ—¥æœŸ: {report_date}

    ã€ä»Šæ—¥å·¥ä½œå†…å®¹ (æ¥è‡ªå›¢é˜Ÿæ—¥å¿—)ã€‘
    {chr(10).join([f"- {l['member_name']} ({l['work_type']}): {l['work_content']}" for l in daily_logs]) if daily_logs else "æ— ä»Šæ—¥æ—¥å¿—è®°å½•"}

    ã€ä»Šæ—¥å®Œæˆä»»åŠ¡ã€‘
    {chr(10).join([f"- {t['task_name']}" for t in completed_tasks]) if completed_tasks else "æ— ä¸»è¦ä»»åŠ¡å®Œæˆ"}

    ã€å½“å‰é‡ç‚¹å…³æ³¨é—®é¢˜/é£é™©ã€‘
    {chr(10).join([f"- [{i['severity']}] {i['description']} (çŠ¶æ€:{i['status']})" for i in active_issues]) if active_issues else "æš‚æ— é‡å¤§é£é™©"}

    ã€æ˜æ—¥è®¡åˆ’ã€‘
    {chr(10).join([f"- {plan}" for plan in tmr_plans]) if tmr_plans else "æŒ‰è®¡åˆ’æ¨è¿›"}
    """

    prompt = f"""
    ä½ æ˜¯ä¸€åä¸“ä¸šçš„é«˜çº§é¡¹ç›®ç»ç†ï¼Œæ­£åœ¨å‘ã€åŒ»é™¢ä¿¡æ¯ç§‘ï¼ˆç”²æ–¹æŠ€æœ¯éƒ¨é—¨ï¼‰ã€‘æ±‡æŠ¥å·¥ä½œã€‚
    è¯·æ ¹æ®ä»¥ä¸‹æ•°æ®ï¼Œå†™ä¸€ä»½ã€Šé¡¹ç›®å®æ–½æ—¥æŠ¥ã€‹ã€‚

    ã€è¦æ±‚ã€‘
    1. **è¯­æ°”ä¸“ä¸š**ï¼šå®¢è§‚ã€å¹²ç»ƒï¼Œä½“ç°æˆ‘ä»¬çš„ä¸“ä¸šç´ å…»ï¼Œé¿å…è¿‡äºå£è¯­åŒ–ã€‚
    2. **ç»“æ„æ¸…æ™°**ï¼šåŒ…å«ã€ä»Šæ—¥è¿›å±•ã€‘ã€ã€é£é™©ä¸é—®é¢˜ã€‘ã€ã€æ˜æ—¥è®¡åˆ’ã€‘ä¸‰ä¸ªæ¿å—ã€‚
    3. **çªå‡ºä»·å€¼**ï¼šé‡ç‚¹æè¿°è§£å†³äº†ä»€ä¹ˆæŠ€æœ¯éš¾é¢˜ã€å®Œæˆäº†å“ªäº›å…³é”®èŠ‚ç‚¹ï¼Œè®©ä¿¡æ¯ç§‘è§‰å¾—æˆ‘ä»¬å·¥ä½œæ‰å®ã€‚
    4. **æ•°æ®é©±åŠ¨**ï¼šé€‚å½“å¼•ç”¨è¿›åº¦ç™¾åˆ†æ¯”æˆ–å…·ä½“ä»»åŠ¡æ•°ã€‚
    5. **é•¿åº¦é€‚ä¸­**ï¼š300-500å­—å·¦å³ï¼Œé€‚åˆå‘é€åˆ°å¾®ä¿¡ç¾¤æˆ–é‚®ä»¶ã€‚

    ã€é¡¹ç›®æ•°æ®ã€‘
    {context}
    """
    
    from ai_utils import call_ai
    report_content = call_ai(prompt, task_type='report')
    
    close_db()
    return jsonify({'report': report_content})

# ========== ç®¡ç†å‘˜ï¼šAIé…ç½®ç®¡ç† API ==========
from services.auth_service import require_auth
import json

@app.route('/api/admin/ai-configs', methods=['GET'])
@require_auth('*')
def get_ai_configs():
    """è·å–æ‰€æœ‰AIé…ç½®ï¼ˆä»…ç®¡ç†å‘˜ï¼‰"""
    print("DEBUG: Accessing get_ai_configs...")
    conn = get_db()
    try:
        configs = conn.execute('SELECT * FROM ai_configs ORDER BY priority').fetchall()
        print(f"DEBUG: Found {len(configs)} configs.")
    except Exception as e:
        print(f"DEBUG: Error querying ai_configs: {e}")
        close_db()
        return jsonify({'success': False, 'message': str(e)}), 500
    close_db()
    
    result = []
    for c in configs:
        config = dict(c)
        # è„±æ•APIå¯†é’¥ï¼Œåªæ˜¾ç¤ºå‰4ä½å’Œå4ä½
        if config['api_key'] and len(config['api_key']) > 8:
            config['api_key_masked'] = config['api_key'][:4] + '****' + config['api_key'][-4:]
        else:
            config['api_key_masked'] = '****'
        # ä¸è¿”å›å®Œæ•´å¯†é’¥
        del config['api_key']
        # è§£æmodels JSON
        if config.get('models'):
            try:
                config['models'] = json.loads(config['models'])
            except:
                config['models'] = []
        else:
            config['models'] = []
        result.append(config)
    
    return jsonify({'success': True, 'data': result})

@app.route('/api/admin/ai-configs', methods=['POST'])
@require_auth('*')
def add_ai_config():
    """æ–°å¢AIé…ç½®ï¼ˆä»…ç®¡ç†å‘˜ï¼‰"""
    data = request.json
    
    if not data.get('name') or not data.get('api_key') or not data.get('base_url'):
        return jsonify({'success': False, 'message': 'åç§°ã€APIå¯†é’¥å’ŒURLä¸ºå¿…å¡«é¡¹'}), 400
    
    # modelsè½¬ä¸ºJSONå­—ç¬¦ä¸²
    models = data.get('models', [])
    if isinstance(models, list):
        models_json = json.dumps(models)
    else:
        models_json = models
    
    conn = get_db()
    try:
        conn.execute('''
            INSERT INTO ai_configs (name, api_key, base_url, models, priority, is_active, updated_at)
            VALUES (?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
        ''', (data['name'], data['api_key'], data['base_url'], models_json, 
              data.get('priority', 1), 1 if data.get('is_active', True) else 0))
        conn.commit()
        close_db()
        return jsonify({'success': True, 'message': 'é…ç½®å·²æ·»åŠ '})
    except sqlite3.IntegrityError:
        close_db()
        return jsonify({'success': False, 'message': 'é…ç½®åç§°å·²å­˜åœ¨'}), 400
    except Exception as e:
        close_db()
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/api/admin/ai-configs/<int:config_id>', methods=['PUT'])
@require_auth('*')
def update_ai_config(config_id):
    """æ›´æ–°AIé…ç½®ï¼ˆä»…ç®¡ç†å‘˜ï¼‰"""
    data = request.json
    conn = get_db()
    
    # æ£€æŸ¥é…ç½®æ˜¯å¦å­˜åœ¨
    existing = conn.execute('SELECT api_key FROM ai_configs WHERE id = ?', (config_id,)).fetchone()
    if not existing:
        close_db()
        return jsonify({'success': False, 'message': 'é…ç½®ä¸å­˜åœ¨'}), 404
    
    # å¦‚æœæ²¡æœ‰æä¾›æ–°å¯†é’¥ï¼Œä¿ç•™åŸå¯†é’¥
    api_key = data.get('api_key') if data.get('api_key') else existing['api_key']
    
    # modelsè½¬ä¸ºJSONå­—ç¬¦ä¸²
    models = data.get('models', [])
    if isinstance(models, list):
        models_json = json.dumps(models)
    else:
        models_json = models
    
    try:
        conn.execute('''
            UPDATE ai_configs SET name=?, api_key=?, base_url=?, models=?, priority=?, is_active=?, updated_at=CURRENT_TIMESTAMP
            WHERE id=?
        ''', (data.get('name'), api_key, data.get('base_url'), models_json,
              data.get('priority', 1), 1 if data.get('is_active', True) else 0, config_id))
        conn.commit()
        close_db()
        return jsonify({'success': True, 'message': 'é…ç½®å·²æ›´æ–°'})
    except Exception as e:
        close_db()
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/api/admin/ai-configs/<int:config_id>', methods=['DELETE'])
@require_auth('*')
def delete_ai_config(config_id):
    """åˆ é™¤AIé…ç½®ï¼ˆä»…ç®¡ç†å‘˜ï¼‰"""
    conn = get_db()
    conn.execute('DELETE FROM ai_configs WHERE id = ?', (config_id,))
    conn.commit()
    close_db()
    return jsonify({'success': True, 'message': 'é…ç½®å·²åˆ é™¤'})

@app.route('/api/admin/ai-configs/<int:config_id>/test', methods=['POST'])
@require_auth('*')
def test_ai_config(config_id):
    """æµ‹è¯•AIé…ç½®è¿é€šæ€§ï¼ˆä»…ç®¡ç†å‘˜ï¼‰"""
    conn = get_db()
    config = conn.execute('SELECT * FROM ai_configs WHERE id = ?', (config_id,)).fetchone()
    close_db()
    
    if not config:
        return jsonify({'success': False, 'message': 'é…ç½®ä¸å­˜åœ¨'}), 404
    
    try:
        # è§£æmodels
        models = []
        if config['models']:
            try:
                models = json.loads(config['models'])
            except:
                models = [config['models']]
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹è¿›è¡Œæµ‹è¯•
        test_model = models[0] if models else 'gpt-3.5-turbo'
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {config['api_key']}"
        }
        payload = {
            "model": test_model,
            "messages": [{"role": "user", "content": "hi"}],
            "max_tokens": 5
        }
        
        start_time = time.time()
        response = requests.post(
            config['base_url'],
            headers=headers,
            data=json.dumps(payload),
            timeout=15
        )
        duration = time.time() - start_time
        
        if response.status_code == 200:
            return jsonify({
                'success': True, 
                'message': f'è¿æ¥æˆåŠŸï¼å“åº”æ—¶é—´: {duration:.2f}s',
                'duration': round(duration, 2)
            })
        else:
            return jsonify({
                'success': False, 
                'message': f'APIè¿”å›é”™è¯¯: HTTP {response.status_code}',
                'details': response.text[:200]
            })
    except requests.Timeout:
        return jsonify({'success': False, 'message': 'è¿æ¥è¶…æ—¶'})
    except Exception as e:
        return jsonify({'success': False, 'message': f'è¿æ¥å¤±è´¥: {str(e)}'})

@app.route('/api/admin/ai-configs/migrate', methods=['POST'])
@require_auth('*')
def migrate_ai_configs():
    """å°†ç¯å¢ƒå˜é‡ä¸­çš„é…ç½®è¿ç§»åˆ°æ•°æ®åº“ï¼ˆä»…ç®¡ç†å‘˜ï¼‰"""
    import os
    
    conn = get_db()
    migrated = []
    
    # TAPI-DeepSeek
    tapi_key = os.environ.get('TAPI_API_KEY')
    if tapi_key:
        existing = conn.execute('SELECT id FROM ai_configs WHERE name = ?', ('TAPI-DeepSeek',)).fetchone()
        if not existing:
            models = json.dumps(["deepseek-v3.2-speciale", "deepseek-v3-2-251201", "deepseek-v3-1-terminus", "deepseek-v3"])
            conn.execute('''
                INSERT INTO ai_configs (name, api_key, base_url, models, priority, is_active)
                VALUES (?, ?, ?, ?, ?, 1)
            ''', ('TAPI-DeepSeek', tapi_key, 'https://tapi.nyc.mn/v1/chat/completions', models, 1))
            migrated.append('TAPI-DeepSeek')
    
    # ChatAnywhere
    chatanywhere_key = os.environ.get('CHATANYWHERE_API_KEY')
    if chatanywhere_key:
        existing = conn.execute('SELECT id FROM ai_configs WHERE name = ?', ('ChatAnywhere',)).fetchone()
        if not existing:
            models = json.dumps(["deepseek-v3", "deepseek-chat", "gpt-4o-mini", "gpt-3.5-turbo"])
            conn.execute('''
                INSERT INTO ai_configs (name, api_key, base_url, models, priority, is_active)
                VALUES (?, ?, ?, ?, ?, 1)
            ''', ('ChatAnywhere', chatanywhere_key, 'https://api.chatanywhere.org/v1/chat/completions', models, 2))
            migrated.append('ChatAnywhere')
    
    conn.commit()
    close_db()
    
    if migrated:
        return jsonify({'success': True, 'message': f'å·²å¯¼å…¥é…ç½®: {", ".join(migrated)}'})
    else:
        return jsonify({'success': True, 'message': 'æ— æ–°é…ç½®å¯å¯¼å…¥ï¼ˆå·²å­˜åœ¨æˆ–ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼‰'})

# ========== æŠ¥å‘Šå½’æ¡£ API ==========
from services.scheduler_service import report_scheduler

@app.route('/api/projects/<int:project_id>/report-archive', methods=['GET'])
def get_report_archive(project_id):
    """è·å–é¡¹ç›®çš„å†å²å½’æ¡£æŠ¥å‘Šåˆ—è¡¨"""
    report_type = request.args.get('type')  # daily / weekly
    limit = request.args.get('limit', 50, type=int)
    conn = get_db()
    query = 'SELECT id, project_id, report_type, report_date, generated_by, created_at FROM report_archive WHERE project_id = ?'
    params = [project_id]
    if report_type:
        query += ' AND report_type = ?'
        params.append(report_type)
    query += ' ORDER BY report_date DESC LIMIT ?'
    params.append(limit)
    rows = conn.execute(query, params).fetchall()
    return jsonify([dict(r) for r in rows])

@app.route('/api/report-archive/<int:archive_id>', methods=['GET'])
def get_report_archive_detail(archive_id):
    """è·å–æŸä»½å½’æ¡£æŠ¥å‘Šçš„è¯¦ç»†å†…å®¹"""
    conn = get_db()
    row = conn.execute('SELECT * FROM report_archive WHERE id = ?', (archive_id,)).fetchone()
    if not row:
        return jsonify({'error': 'æŠ¥å‘Šä¸å­˜åœ¨'}), 404
    return jsonify(dict(row))

@app.route('/api/projects/<int:project_id>/report-archive/generate', methods=['POST'])
def generate_report_archive(project_id):
    """æ‰‹åŠ¨è§¦å‘ä¸ºæŒ‡å®šé¡¹ç›®ç”Ÿæˆå½“æ—¥æŠ¥å‘Š"""
    data = request.json or {}
    report_type = data.get('report_type', 'daily')
    force = data.get('force', False)
    try:
        result = report_scheduler.generate_for_project(project_id, report_type, force)
        return jsonify(result)
    except Exception as e:
        return jsonify({'error': str(e)}), 500



# ========== å­˜å‚¨é…ç½® API (Baidu Netdisk) ==========
from storage_service import storage_service

@app.route('/api/admin/storage/auth-url', methods=['GET'])
@require_auth('*')
def get_storage_auth_url():
    url = storage_service.get_auth_url()
    return jsonify({'url': url})

@app.route('/api/admin/storage/callback', methods=['POST'])
@require_auth('*')
def storage_auth_callback():
    data = request.json or {}
    code = data.get('code')
    if not code:
        return jsonify({'success': False, 'message': 'Missing auth code'}), 400
    
    try:
        success, message = storage_service.authenticate(code)
        if success:
             return jsonify({'success': True, 'message': message})
        else:
             return jsonify({'success': False, 'message': f'Authorization failed: {message}'}), 400
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/api/admin/storage/status', methods=['GET'])
@require_auth('*')
def get_storage_status():
    is_auth = storage_service.is_authorized()
    return jsonify({
        'is_authorized': is_auth
    })

@app.route('/api/admin/storage/config', methods=['GET'])
@require_auth('admin')
def get_storage_config():
    try:
        config = storage_service.get_config()
        # Hide secret keys in response
        safe_config = config.copy()
        if 'r2' in safe_config:
            r2_conf = safe_config['r2'].copy()
            if r2_conf.get('secret_key'):
                r2_conf['secret_key'] = '******'
            safe_config['r2'] = r2_conf
        return jsonify(safe_config)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/admin/storage/config', methods=['POST'])
@require_auth('admin')
def update_storage_config():
    try:
        data = request.get_json()
        current_config = storage_service.get_config()
        
        # Handle password masking
        if data.get('type') == 'r2' and 'r2' in data:
            new_r2 = data['r2']
            if new_r2.get('secret_key') == '******':
                old_r2 = current_config.get('r2', {})
                new_r2['secret_key'] = old_r2.get('secret_key')
        
        if storage_service.update_config(data):
            return jsonify({'success': True, 'message': 'Storage configuration saved'})
        else:
            return jsonify({'success': False, 'message': 'Failed to save configuration'}), 500
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/api/admin/storage/test-r2', methods=['POST'])
@require_auth('admin')
def test_r2_connection():
    try:
        data = request.get_json()
        # Handle masked password
        secret_key = data.get('secret_key')
        if secret_key == '******':
             current_config = storage_service.get_config()
             old_r2 = current_config.get('r2', {})
             secret_key = old_r2.get('secret_key')

        from storage_service import R2Storage
        r2 = R2Storage(
            endpoint_url=data.get('endpoint'),
            access_key=data.get('access_key'),
            secret_key=secret_key,
            bucket_name=data.get('bucket_name')
        )
        if r2.is_authorized():
            return jsonify({'success': True, 'message': 'Connection successful'})
        else:
            return jsonify({'success': False, 'message': 'Connection failed (Check logs)'}), 400
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)}), 500


if __name__ == '__main__':
    with app.app_context():
        init_db()
        reload_notification_config()
    # å¯åŠ¨æŠ¥å‘Šè‡ªåŠ¨å½’æ¡£è°ƒåº¦å™¨
    report_scheduler.start()
    app.run(debug=True, host='0.0.0.0', port=5000)

